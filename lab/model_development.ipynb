{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "5519f877",
   "metadata": {},
   "source": [
    "# Get The Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "5cae94c5",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import sys\n",
    "import os\n",
    "proj_root = os.path.abspath(\"..\")  \n",
    "if proj_root not in sys.path:\n",
    "    sys.path.insert(0, proj_root)\n",
    "\n",
    "from ml.preprocessing import Preprocessor, Initial_Transformation  # noqa: E402\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "e375d07b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "============================================================\n",
      "FEATURE TRANSFORMATION RESULTS\n",
      "============================================================\n",
      "[[ 1.00000000e+00  1.00000000e+00  0.00000000e+00  0.00000000e+00\n",
      "   0.00000000e+00  0.00000000e+00  0.00000000e+00  0.00000000e+00\n",
      "   0.00000000e+00  1.00000000e+00  0.00000000e+00  0.00000000e+00\n",
      "   0.00000000e+00  1.00000000e+00  0.00000000e+00  0.00000000e+00\n",
      "   0.00000000e+00  0.00000000e+00  0.00000000e+00  0.00000000e+00\n",
      "   0.00000000e+00  0.00000000e+00  0.00000000e+00  0.00000000e+00\n",
      "   0.00000000e+00  0.00000000e+00  0.00000000e+00  0.00000000e+00\n",
      "   0.00000000e+00  0.00000000e+00  0.00000000e+00  0.00000000e+00\n",
      "   0.00000000e+00  0.00000000e+00  0.00000000e+00  0.00000000e+00\n",
      "   0.00000000e+00  0.00000000e+00  0.00000000e+00  0.00000000e+00\n",
      "   0.00000000e+00  0.00000000e+00  0.00000000e+00  0.00000000e+00\n",
      "   1.00000000e+00  0.00000000e+00  0.00000000e+00  0.00000000e+00\n",
      "   0.00000000e+00  1.00000000e+00  0.00000000e+00  0.00000000e+00\n",
      "   0.00000000e+00  0.00000000e+00  0.00000000e+00  0.00000000e+00\n",
      "   0.00000000e+00  0.00000000e+00  0.00000000e+00  0.00000000e+00\n",
      "   0.00000000e+00  0.00000000e+00  0.00000000e+00  0.00000000e+00\n",
      "   0.00000000e+00  0.00000000e+00  0.00000000e+00  0.00000000e+00\n",
      "   0.00000000e+00  0.00000000e+00  0.00000000e+00  0.00000000e+00\n",
      "  -2.46870780e-01  2.99200044e-01  1.18910765e-01  2.00000000e+00\n",
      "   2.00000000e+00  5.77929400e-01  6.05904102e-01  6.57489138e-01\n",
      "   6.26538651e-01 -1.53302012e-01 -3.22126809e-01 -1.21606945e+00\n",
      "  -3.31401050e-01 -3.05636976e-01 -3.20148722e-01  1.42396740e+00\n",
      "   1.50000000e+01  1.80000000e+01  3.00000000e+00  1.80000000e+01\n",
      "   3.00000000e+00 -1.00000000e+00 -1.00000000e+00  0.00000000e+00]\n",
      " [ 0.00000000e+00  1.00000000e+00  0.00000000e+00  0.00000000e+00\n",
      "   0.00000000e+00  0.00000000e+00  0.00000000e+00  0.00000000e+00\n",
      "   0.00000000e+00  0.00000000e+00  0.00000000e+00  0.00000000e+00\n",
      "   1.00000000e+00  0.00000000e+00  0.00000000e+00  0.00000000e+00\n",
      "   0.00000000e+00  0.00000000e+00  0.00000000e+00  0.00000000e+00\n",
      "   1.00000000e+00  0.00000000e+00  0.00000000e+00  0.00000000e+00\n",
      "   0.00000000e+00  0.00000000e+00  0.00000000e+00  0.00000000e+00\n",
      "   0.00000000e+00  0.00000000e+00  0.00000000e+00  0.00000000e+00\n",
      "   0.00000000e+00  0.00000000e+00  0.00000000e+00  0.00000000e+00\n",
      "   0.00000000e+00  0.00000000e+00  0.00000000e+00  0.00000000e+00\n",
      "   0.00000000e+00  1.00000000e+00  0.00000000e+00  0.00000000e+00\n",
      "   0.00000000e+00  0.00000000e+00  0.00000000e+00  0.00000000e+00\n",
      "   0.00000000e+00  1.00000000e+00  0.00000000e+00  0.00000000e+00\n",
      "   0.00000000e+00  0.00000000e+00  0.00000000e+00  0.00000000e+00\n",
      "   0.00000000e+00  0.00000000e+00  0.00000000e+00  0.00000000e+00\n",
      "   0.00000000e+00  0.00000000e+00  0.00000000e+00  0.00000000e+00\n",
      "   0.00000000e+00  0.00000000e+00  0.00000000e+00  0.00000000e+00\n",
      "   0.00000000e+00  0.00000000e+00  0.00000000e+00  0.00000000e+00\n",
      "  -1.37221945e-02  4.57446300e-01 -3.38574372e-01  1.00000000e+00\n",
      "   2.00000000e+00  4.85546954e-01 -6.97543141e-01 -4.60104963e-01\n",
      "   7.06672038e-01  7.50507295e-01 -3.23863047e-01 -1.21606945e+00\n",
      "  -3.28054496e-01 -3.17460637e-01 -3.20148722e-01  1.42396740e+00\n",
      "   1.40000000e+01  1.50000000e+01  2.00000000e+00  9.00000000e+00\n",
      "   3.00000000e+00 -1.00000000e+00 -1.00000000e+00  0.00000000e+00]\n",
      " [ 2.00000000e+00  1.00000000e+00  0.00000000e+00  0.00000000e+00\n",
      "   0.00000000e+00  0.00000000e+00  0.00000000e+00  0.00000000e+00\n",
      "   0.00000000e+00  0.00000000e+00  1.00000000e+00  0.00000000e+00\n",
      "   0.00000000e+00  0.00000000e+00  0.00000000e+00  0.00000000e+00\n",
      "   0.00000000e+00  0.00000000e+00  1.00000000e+00  0.00000000e+00\n",
      "   0.00000000e+00  0.00000000e+00  0.00000000e+00  0.00000000e+00\n",
      "   0.00000000e+00  0.00000000e+00  0.00000000e+00  0.00000000e+00\n",
      "   0.00000000e+00  0.00000000e+00  0.00000000e+00  0.00000000e+00\n",
      "   0.00000000e+00  0.00000000e+00  0.00000000e+00  0.00000000e+00\n",
      "   0.00000000e+00  0.00000000e+00  0.00000000e+00  0.00000000e+00\n",
      "   0.00000000e+00  0.00000000e+00  0.00000000e+00  0.00000000e+00\n",
      "   1.00000000e+00  0.00000000e+00  0.00000000e+00  0.00000000e+00\n",
      "   0.00000000e+00  1.00000000e+00  0.00000000e+00  0.00000000e+00\n",
      "   0.00000000e+00  0.00000000e+00  0.00000000e+00  0.00000000e+00\n",
      "   0.00000000e+00  0.00000000e+00  0.00000000e+00  0.00000000e+00\n",
      "   0.00000000e+00  0.00000000e+00  0.00000000e+00  0.00000000e+00\n",
      "   0.00000000e+00  0.00000000e+00  0.00000000e+00  0.00000000e+00\n",
      "   0.00000000e+00  0.00000000e+00  0.00000000e+00  0.00000000e+00\n",
      "  -3.66429734e-15  0.00000000e+00  0.00000000e+00  1.00000000e+00\n",
      "   2.00000000e+00  7.02917415e-01  6.88662657e-01  8.41684385e-01\n",
      "  -2.06925463e-02  7.50507295e-01 -3.30807999e-01 -2.00127596e-02\n",
      "  -3.48133818e-01 -3.13913538e-01 -3.20148722e-01 -1.00159488e+00\n",
      "   1.50000000e+01  1.80000000e+01  2.00000000e+00  1.80000000e+01\n",
      "   3.00000000e+00 -1.00000000e+00 -1.00000000e+00  1.00000000e+00]\n",
      " [ 0.00000000e+00  1.00000000e+00  0.00000000e+00  0.00000000e+00\n",
      "   0.00000000e+00  0.00000000e+00  0.00000000e+00  0.00000000e+00\n",
      "   0.00000000e+00  1.00000000e+00  0.00000000e+00  0.00000000e+00\n",
      "   0.00000000e+00  0.00000000e+00  0.00000000e+00  0.00000000e+00\n",
      "   0.00000000e+00  0.00000000e+00  0.00000000e+00  0.00000000e+00\n",
      "   1.00000000e+00  0.00000000e+00  0.00000000e+00  0.00000000e+00\n",
      "   0.00000000e+00  0.00000000e+00  0.00000000e+00  0.00000000e+00\n",
      "   0.00000000e+00  0.00000000e+00  0.00000000e+00  0.00000000e+00\n",
      "   0.00000000e+00  0.00000000e+00  0.00000000e+00  0.00000000e+00\n",
      "   0.00000000e+00  0.00000000e+00  0.00000000e+00  0.00000000e+00\n",
      "   0.00000000e+00  0.00000000e+00  0.00000000e+00  0.00000000e+00\n",
      "   0.00000000e+00  1.00000000e+00  0.00000000e+00  0.00000000e+00\n",
      "   0.00000000e+00  1.00000000e+00  0.00000000e+00  0.00000000e+00\n",
      "   0.00000000e+00  0.00000000e+00  0.00000000e+00  0.00000000e+00\n",
      "   0.00000000e+00  0.00000000e+00  0.00000000e+00  0.00000000e+00\n",
      "   0.00000000e+00  0.00000000e+00  0.00000000e+00  0.00000000e+00\n",
      "   0.00000000e+00  0.00000000e+00  0.00000000e+00  0.00000000e+00\n",
      "   0.00000000e+00  0.00000000e+00  0.00000000e+00  0.00000000e+00\n",
      "   2.49705484e-01 -4.12044680e-01  1.01108905e+00  1.00000000e+00\n",
      "   1.00000000e+00  4.85546954e-01 -6.97543141e-01 -4.60104963e-01\n",
      "   6.57359184e-01  9.42224421e-01 -3.32544236e-01 -1.21606945e+00\n",
      "  -3.48133818e-01 -3.26919565e-01 -3.20148722e-01 -1.00159488e+00\n",
      "   1.20000000e+01  1.30000000e+01  2.00000000e+00  7.00000000e+00\n",
      "   3.00000000e+00 -1.00000000e+00 -1.00000000e+00  0.00000000e+00]\n",
      " [ 0.00000000e+00  1.00000000e+00  0.00000000e+00  0.00000000e+00\n",
      "   0.00000000e+00  0.00000000e+00  0.00000000e+00  0.00000000e+00\n",
      "   0.00000000e+00  0.00000000e+00  1.00000000e+00  0.00000000e+00\n",
      "   0.00000000e+00  0.00000000e+00  0.00000000e+00  0.00000000e+00\n",
      "   0.00000000e+00  0.00000000e+00  0.00000000e+00  0.00000000e+00\n",
      "   1.00000000e+00  0.00000000e+00  0.00000000e+00  0.00000000e+00\n",
      "   0.00000000e+00  0.00000000e+00  0.00000000e+00  0.00000000e+00\n",
      "   0.00000000e+00  0.00000000e+00  0.00000000e+00  0.00000000e+00\n",
      "   0.00000000e+00  0.00000000e+00  0.00000000e+00  0.00000000e+00\n",
      "   0.00000000e+00  0.00000000e+00  0.00000000e+00  0.00000000e+00\n",
      "   0.00000000e+00  1.00000000e+00  0.00000000e+00  0.00000000e+00\n",
      "   0.00000000e+00  0.00000000e+00  0.00000000e+00  0.00000000e+00\n",
      "   0.00000000e+00  1.00000000e+00  0.00000000e+00  0.00000000e+00\n",
      "   0.00000000e+00  0.00000000e+00  0.00000000e+00  0.00000000e+00\n",
      "   0.00000000e+00  0.00000000e+00  0.00000000e+00  0.00000000e+00\n",
      "   0.00000000e+00  0.00000000e+00  0.00000000e+00  0.00000000e+00\n",
      "   0.00000000e+00  0.00000000e+00  0.00000000e+00  0.00000000e+00\n",
      "   0.00000000e+00  0.00000000e+00  0.00000000e+00  0.00000000e+00\n",
      "  -1.52024487e-01  2.95006851e-02  3.62297462e-01  1.00000000e+00\n",
      "   2.00000000e+00  5.18152523e-01 -6.97543141e-01 -4.39749527e-01\n",
      "   5.95718118e-01  3.67073044e-01 -3.30807999e-01 -2.00127596e-02\n",
      "  -3.58173480e-01 -3.25737199e-01 -3.20148722e-01 -1.00159488e+00\n",
      "   1.50000000e+01  1.50000000e+01  2.00000000e+00  9.00000000e+00\n",
      "   3.00000000e+00 -1.00000000e+00  2.00000000e+00  1.00000000e+00]\n",
      " [ 0.00000000e+00  1.00000000e+00  0.00000000e+00  0.00000000e+00\n",
      "   0.00000000e+00  0.00000000e+00  0.00000000e+00  0.00000000e+00\n",
      "   0.00000000e+00  1.00000000e+00  0.00000000e+00  0.00000000e+00\n",
      "   0.00000000e+00  0.00000000e+00  0.00000000e+00  0.00000000e+00\n",
      "   0.00000000e+00  0.00000000e+00  0.00000000e+00  0.00000000e+00\n",
      "   1.00000000e+00  0.00000000e+00  0.00000000e+00  0.00000000e+00\n",
      "   0.00000000e+00  0.00000000e+00  0.00000000e+00  0.00000000e+00\n",
      "   0.00000000e+00  0.00000000e+00  0.00000000e+00  0.00000000e+00\n",
      "   0.00000000e+00  0.00000000e+00  0.00000000e+00  0.00000000e+00\n",
      "   0.00000000e+00  0.00000000e+00  0.00000000e+00  0.00000000e+00\n",
      "   0.00000000e+00  0.00000000e+00  0.00000000e+00  0.00000000e+00\n",
      "   1.00000000e+00  0.00000000e+00  0.00000000e+00  0.00000000e+00\n",
      "   0.00000000e+00  1.00000000e+00  0.00000000e+00  0.00000000e+00\n",
      "   0.00000000e+00  0.00000000e+00  0.00000000e+00  0.00000000e+00\n",
      "   0.00000000e+00  0.00000000e+00  0.00000000e+00  0.00000000e+00\n",
      "   0.00000000e+00  0.00000000e+00  0.00000000e+00  0.00000000e+00\n",
      "   0.00000000e+00  0.00000000e+00  0.00000000e+00  0.00000000e+00\n",
      "   0.00000000e+00  0.00000000e+00  0.00000000e+00  0.00000000e+00\n",
      "  -2.46870780e-01  2.35333185e-01  1.45457892e-01  1.00000000e+00\n",
      "   2.00000000e+00  4.85546954e-01  7.09352295e-01  6.54777602e-01\n",
      "   2.13543506e-01  4.05416469e-01 -3.25599285e-01 -2.00127596e-02\n",
      "  -2.94588958e-01 -3.13913538e-01 -3.20148722e-01  1.42396740e+00\n",
      "   1.50000000e+01  1.70000000e+01  3.00000000e+00  1.50000000e+01\n",
      "   3.00000000e+00 -1.00000000e+00 -1.00000000e+00  1.00000000e+00]\n",
      " [ 0.00000000e+00  1.00000000e+00  0.00000000e+00  0.00000000e+00\n",
      "   0.00000000e+00  0.00000000e+00  0.00000000e+00  0.00000000e+00\n",
      "   0.00000000e+00  0.00000000e+00  1.00000000e+00  0.00000000e+00\n",
      "   0.00000000e+00  0.00000000e+00  0.00000000e+00  0.00000000e+00\n",
      "   0.00000000e+00  0.00000000e+00  0.00000000e+00  0.00000000e+00\n",
      "   0.00000000e+00  1.00000000e+00  0.00000000e+00  0.00000000e+00\n",
      "   0.00000000e+00  0.00000000e+00  0.00000000e+00  0.00000000e+00\n",
      "   0.00000000e+00  0.00000000e+00  0.00000000e+00  0.00000000e+00\n",
      "   0.00000000e+00  0.00000000e+00  0.00000000e+00  0.00000000e+00\n",
      "   0.00000000e+00  0.00000000e+00  0.00000000e+00  0.00000000e+00\n",
      "   0.00000000e+00  1.00000000e+00  0.00000000e+00  0.00000000e+00\n",
      "   0.00000000e+00  0.00000000e+00  0.00000000e+00  0.00000000e+00\n",
      "   0.00000000e+00  1.00000000e+00  0.00000000e+00  0.00000000e+00\n",
      "   0.00000000e+00  0.00000000e+00  0.00000000e+00  0.00000000e+00\n",
      "   0.00000000e+00  0.00000000e+00  0.00000000e+00  0.00000000e+00\n",
      "   0.00000000e+00  0.00000000e+00  0.00000000e+00  0.00000000e+00\n",
      "   0.00000000e+00  0.00000000e+00  0.00000000e+00  0.00000000e+00\n",
      "   0.00000000e+00  0.00000000e+00  0.00000000e+00  0.00000000e+00\n",
      "  -1.52024487e-01  4.85184200e-02  3.62297462e-01  1.00000000e+00\n",
      "   1.00000000e+00  5.29021046e-01 -6.97543141e-01 -4.32964382e-01\n",
      "   5.95718118e-01  9.42224421e-01 -3.32544236e-01 -1.21606945e+00\n",
      "  -3.78252802e-01 -3.28101931e-01 -3.20148722e-01 -1.00159488e+00\n",
      "   1.30000000e+01  1.30000000e+01  2.00000000e+00  9.00000000e+00\n",
      "   3.00000000e+00 -1.00000000e+00 -1.00000000e+00  0.00000000e+00]\n",
      " [ 1.00000000e+00  1.00000000e+00  0.00000000e+00  0.00000000e+00\n",
      "   0.00000000e+00  0.00000000e+00  0.00000000e+00  0.00000000e+00\n",
      "   0.00000000e+00  1.00000000e+00  0.00000000e+00  0.00000000e+00\n",
      "   0.00000000e+00  0.00000000e+00  0.00000000e+00  0.00000000e+00\n",
      "   0.00000000e+00  0.00000000e+00  0.00000000e+00  0.00000000e+00\n",
      "   1.00000000e+00  0.00000000e+00  0.00000000e+00  0.00000000e+00\n",
      "   0.00000000e+00  0.00000000e+00  0.00000000e+00  0.00000000e+00\n",
      "   0.00000000e+00  0.00000000e+00  0.00000000e+00  0.00000000e+00\n",
      "   0.00000000e+00  0.00000000e+00  0.00000000e+00  0.00000000e+00\n",
      "   0.00000000e+00  0.00000000e+00  0.00000000e+00  0.00000000e+00\n",
      "   0.00000000e+00  0.00000000e+00  0.00000000e+00  0.00000000e+00\n",
      "   1.00000000e+00  0.00000000e+00  0.00000000e+00  0.00000000e+00\n",
      "   0.00000000e+00  1.00000000e+00  0.00000000e+00  0.00000000e+00\n",
      "   0.00000000e+00  0.00000000e+00  0.00000000e+00  0.00000000e+00\n",
      "   0.00000000e+00  0.00000000e+00  0.00000000e+00  0.00000000e+00\n",
      "   0.00000000e+00  0.00000000e+00  0.00000000e+00  0.00000000e+00\n",
      "   0.00000000e+00  0.00000000e+00  0.00000000e+00  0.00000000e+00\n",
      "   0.00000000e+00  0.00000000e+00  0.00000000e+00  0.00000000e+00\n",
      "  -3.43948953e-01  1.34689144e-01  3.81483551e-01  1.00000000e+00\n",
      "   2.00000000e+00  6.37706276e-01  6.16248921e-01  7.20838178e-01\n",
      "   5.95718118e-01  5.40531395e-01 -3.16049977e-01 -2.00127596e-02\n",
      "  -2.14271668e-01 -2.99725145e-01 -3.20148722e-01  1.42396740e+00\n",
      "   1.40000000e+01  1.70000000e+01  2.00000000e+00  1.70000000e+01\n",
      "   3.00000000e+00 -1.00000000e+00 -1.00000000e+00  1.00000000e+00]\n",
      " [ 1.00000000e+00  1.00000000e+00  0.00000000e+00  0.00000000e+00\n",
      "   0.00000000e+00  0.00000000e+00  0.00000000e+00  0.00000000e+00\n",
      "   0.00000000e+00  1.00000000e+00  0.00000000e+00  0.00000000e+00\n",
      "   0.00000000e+00  0.00000000e+00  0.00000000e+00  0.00000000e+00\n",
      "   0.00000000e+00  0.00000000e+00  0.00000000e+00  0.00000000e+00\n",
      "   1.00000000e+00  0.00000000e+00  0.00000000e+00  0.00000000e+00\n",
      "   0.00000000e+00  0.00000000e+00  0.00000000e+00  0.00000000e+00\n",
      "   0.00000000e+00  0.00000000e+00  0.00000000e+00  0.00000000e+00\n",
      "   0.00000000e+00  0.00000000e+00  0.00000000e+00  0.00000000e+00\n",
      "   0.00000000e+00  0.00000000e+00  0.00000000e+00  0.00000000e+00\n",
      "   0.00000000e+00  0.00000000e+00  0.00000000e+00  0.00000000e+00\n",
      "   1.00000000e+00  0.00000000e+00  0.00000000e+00  0.00000000e+00\n",
      "   0.00000000e+00  1.00000000e+00  0.00000000e+00  0.00000000e+00\n",
      "   0.00000000e+00  0.00000000e+00  0.00000000e+00  0.00000000e+00\n",
      "   0.00000000e+00  0.00000000e+00  0.00000000e+00  0.00000000e+00\n",
      "   0.00000000e+00  0.00000000e+00  0.00000000e+00  0.00000000e+00\n",
      "   0.00000000e+00  0.00000000e+00  0.00000000e+00  0.00000000e+00\n",
      "   0.00000000e+00  0.00000000e+00  0.00000000e+00  0.00000000e+00\n",
      "  -3.43948953e-01  1.34689144e-01  3.81483551e-01  1.00000000e+00\n",
      "   2.00000000e+00  6.37706276e-01  6.16248921e-01  7.20838178e-01\n",
      "   5.95718118e-01  2.84908561e-01 -3.28203642e-01 -1.21606945e+00\n",
      "  -3.61520033e-01 -3.21007735e-01 -3.20148722e-01 -1.00159488e+00\n",
      "   1.50000000e+01  1.70000000e+01  2.00000000e+00  1.70000000e+01\n",
      "   3.00000000e+00 -1.00000000e+00 -1.00000000e+00  0.00000000e+00]\n",
      " [ 0.00000000e+00  1.00000000e+00  0.00000000e+00  0.00000000e+00\n",
      "   0.00000000e+00  0.00000000e+00  0.00000000e+00  0.00000000e+00\n",
      "   0.00000000e+00  0.00000000e+00  1.00000000e+00  0.00000000e+00\n",
      "   0.00000000e+00  0.00000000e+00  0.00000000e+00  0.00000000e+00\n",
      "   0.00000000e+00  0.00000000e+00  0.00000000e+00  0.00000000e+00\n",
      "   1.00000000e+00  0.00000000e+00  0.00000000e+00  0.00000000e+00\n",
      "   0.00000000e+00  0.00000000e+00  0.00000000e+00  0.00000000e+00\n",
      "   0.00000000e+00  0.00000000e+00  0.00000000e+00  0.00000000e+00\n",
      "   0.00000000e+00  0.00000000e+00  0.00000000e+00  0.00000000e+00\n",
      "   0.00000000e+00  0.00000000e+00  0.00000000e+00  0.00000000e+00\n",
      "   0.00000000e+00  1.00000000e+00  0.00000000e+00  0.00000000e+00\n",
      "   0.00000000e+00  0.00000000e+00  0.00000000e+00  0.00000000e+00\n",
      "   0.00000000e+00  1.00000000e+00  0.00000000e+00  0.00000000e+00\n",
      "   0.00000000e+00  0.00000000e+00  0.00000000e+00  0.00000000e+00\n",
      "   0.00000000e+00  0.00000000e+00  0.00000000e+00  0.00000000e+00\n",
      "   0.00000000e+00  0.00000000e+00  0.00000000e+00  0.00000000e+00\n",
      "   0.00000000e+00  0.00000000e+00  0.00000000e+00  0.00000000e+00\n",
      "   0.00000000e+00  0.00000000e+00  0.00000000e+00  0.00000000e+00\n",
      "  -1.52024487e-01  2.95006851e-02  3.62297462e-01  1.00000000e+00\n",
      "   2.00000000e+00  5.18152523e-01 -6.97543141e-01 -4.39749527e-01\n",
      "   5.95718118e-01  1.75355918e-01 -3.33412355e-01 -1.21606945e+00\n",
      "  -3.88292463e-01 -3.29284297e-01 -3.20148722e-01 -1.00159488e+00\n",
      "   1.40000000e+01  1.70000000e+01  2.00000000e+00  9.00000000e+00\n",
      "   3.00000000e+00 -1.00000000e+00 -1.00000000e+00  0.00000000e+00]]\n",
      "(508, 96)\n"
     ]
    }
   ],
   "source": [
    "mobile , df = Initial_Transformation(file_path=\"../ml/dataset\")\n",
    "preprocessing = Preprocessor()\n",
    "\n",
    "preprocessing.fit(mobile)\n",
    "transformed = preprocessing.transform(mobile)\n",
    "print(\"=\" * 60)\n",
    "print(\"FEATURE TRANSFORMATION RESULTS\")\n",
    "print(\"=\" * 60)\n",
    "\n",
    "\n",
    "print(transformed[50:60])\n",
    "print(transformed.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "91a2a3bd",
   "metadata": {},
   "source": [
    "-----"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "718cbd7b",
   "metadata": {},
   "source": [
    "# MlFlow Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "8b55059b",
   "metadata": {},
   "outputs": [],
   "source": [
    "from mlflow import MlflowClient\n",
    "from pprint import pprint\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "f9f8a5ab",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[<Experiment: artifact_location='mlflow-artifacts:/918627768166686221', creation_time=1761695007629, experiment_id='918627768166686221', last_update_time=1761740089160, lifecycle_stage='active', name='Link', tags={'mlflow.experimentKind': 'custom_model_development',\n",
      " 'mlflow.note.content': 'This is Linkage experiment',\n",
      " 'project_name': 'stapler_clustering_traditional_ML'}>, <Experiment: artifact_location='mlflow-artifacts:/694982361173019963', creation_time=1761690946251, experiment_id='694982361173019963', last_update_time=1761739926270, lifecycle_stage='active', name='K-means', tags={'mlflow.experimentKind': 'custom_model_development',\n",
      " 'mlflow.note.content': 'This is K-means experiment',\n",
      " 'project_name': 'stapler_clustering_traditional_ML'}>, <Experiment: artifact_location='mlflow-artifacts:/0', creation_time=1761057273861, experiment_id='0', last_update_time=1761057273861, lifecycle_stage='active', name='Default', tags={'mlflow.experimentKind': 'custom_model_development'}>]\n"
     ]
    }
   ],
   "source": [
    "client = MlflowClient(tracking_uri=\"http://127.0.0.1:8080\")\n",
    "all_experiments = client.search_experiments()\n",
    "\n",
    "print(all_experiments)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "26397dfc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'lifecycle_stage': 'active', 'name': 'Default'}\n"
     ]
    }
   ],
   "source": [
    "default_experiment = [\n",
    "    {\"name\": experiment.name, \"lifecycle_stage\": experiment.lifecycle_stage}\n",
    "    for experiment in all_experiments\n",
    "    if experiment.name == \"Default\"\n",
    "][0]\n",
    "\n",
    "pprint(default_experiment)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "04eb1502",
   "metadata": {},
   "outputs": [],
   "source": [
    "import mlflow\n",
    "\n",
    "# Use the fluent API to set the tracking uri and the active experiment\n",
    "mlflow.set_tracking_uri(\"http://127.0.0.1:8080\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6d4dc30e",
   "metadata": {},
   "source": [
    "# FlexibleNestedClusteringSystem"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "e22865eb",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from typing import Dict, Any\n",
    "from sklearn.cluster import (AgglomerativeClustering, KMeans, DBSCAN, \n",
    "                           SpectralClustering, MiniBatchKMeans)\n",
    "from sklearn.base import BaseEstimator, ClusterMixin\n",
    "\n",
    "class FlexibleNestedClusteringSystem(BaseEstimator, ClusterMixin):\n",
    "    def __init__(self, \n",
    "                 level1_config: Dict[str, Any],\n",
    "                 level2_config: Dict[str, Any], \n",
    "                 level3_config: Dict[str, Any],\n",
    "                 min_samples_per_final_cluster: int = 3,\n",
    "                 original_data=None):\n",
    "        \"\"\"\n",
    "        Initialize flexible nested clustering system.\n",
    "\n",
    "        Args:\n",
    "            level1_config: Configuration for Level 1 clustering\n",
    "            level2_config: Configuration for Level 2 clustering  \n",
    "            level3_config: Configuration for Level 3 clustering\n",
    "            min_samples_per_final_cluster: Minimum samples in final clusters\n",
    "            original_data: The original (untransformed) data (optional, used for reporting only)\n",
    "            \n",
    "        Example configs:\n",
    "        level1_config = {\n",
    "            'algorithm': 'AgglomerativeClustering',\n",
    "            'n_clusters': 5,\n",
    "            'linkage': 'complete'\n",
    "        }\n",
    "        level2_config = {\n",
    "            'algorithm': 'KMeans', \n",
    "            'n_clusters': 3,\n",
    "            'random_state': 42\n",
    "        }\n",
    "        level3_config = {\n",
    "            'algorithm': 'GaussianMixture',\n",
    "            'n_components': 2,\n",
    "            'random_state': 42\n",
    "        }\n",
    "        \"\"\"\n",
    "        self.level1_config = level1_config\n",
    "        self.level2_config = level2_config\n",
    "        self.level3_config = level3_config\n",
    "        self.min_samples_per_final_cluster = min_samples_per_final_cluster\n",
    "        \n",
    "        # Store the original data, used for summary/visualization only\n",
    "        self.original_data = original_data\n",
    "        \n",
    "        # Storage for models and results\n",
    "        self.level1_model = None\n",
    "        self.level2_models = {}\n",
    "        self.level3_models = {}\n",
    "        self.level1_labels = None\n",
    "        self.level2_labels = {}\n",
    "        self.level3_labels = {}\n",
    "        self.sample_assignments = None\n",
    "        self.cluster_hierarchy = {}\n",
    "    \n",
    "    def _create_algorithm(self, config: Dict[str, Any]):\n",
    "        \"\"\"Create clustering algorithm from configuration.\"\"\"\n",
    "        algorithm_name = config['algorithm']\n",
    "        params = {k: v for k, v in config.items() if k != 'algorithm'}\n",
    "        \n",
    "        algorithm_map = {\n",
    "            'AgglomerativeClustering': AgglomerativeClustering,\n",
    "            'KMeans': KMeans,\n",
    "            'DBSCAN': DBSCAN,\n",
    "            'SpectralClustering': SpectralClustering,\n",
    "            'MiniBatchKMeans': MiniBatchKMeans,\n",
    "        }\n",
    "        \n",
    "        if algorithm_name not in algorithm_map:\n",
    "            raise ValueError(f\"Unsupported algorithm: {algorithm_name}\")\n",
    "        \n",
    "        return algorithm_map[algorithm_name](**params)\n",
    "    \n",
    "    def fit(self, X, y=None, sample_names=None):\n",
    "        if sample_names is None:\n",
    "            sample_names = [f\"Sample_{i}\" for i in range(len(X))]\n",
    "        \n",
    "        self.sample_names = sample_names\n",
    "        self.n_samples = len(X)\n",
    "        \n",
    "        print(\"üîß Starting Flexible Nested Clustering\")\n",
    "        print(f\"üìä Data shape: {X.shape}\")\n",
    "        print(f\"üéØ Level 1: {self.level1_config['algorithm']} ‚Üí {self.level2_config['algorithm']} ‚Üí {self.level3_config['algorithm']}\")\n",
    "        print(\"=\" * 60)\n",
    "        \n",
    "        # Level 1: Top-level clustering\n",
    "        print(f\"üìç Level 1: {self.level1_config['algorithm']} clustering...\")\n",
    "        self._fit_level1(X)\n",
    "        \n",
    "        # Level 2: Sub-clustering\n",
    "        print(f\"üìç Level 2: {self.level2_config['algorithm']} sub-clustering...\")\n",
    "        self._fit_level2(X)\n",
    "        \n",
    "        # Level 3: Sub-sub-clustering\n",
    "        print(f\"üìç Level 3: {self.level3_config['algorithm']} sub-sub-clustering...\")\n",
    "        self._fit_level3(X)\n",
    "        \n",
    "        # # Build hierarchy\n",
    "        self._build_hierarchy()\n",
    "        \n",
    "        print(\"‚úÖ Flexible nested clustering completed!\")\n",
    "\n",
    "        self._print_hierarchy_summary(original_data=self.original_data)\n",
    "        \n",
    "        return self\n",
    "\n",
    "    def _fit_level1(self, X):\n",
    "        \"\"\"Fit Level 1 clustering (top level).\"\"\"\n",
    "        self.level1_model = self._create_algorithm(self.level1_config)\n",
    "        \n",
    "        # Handle different algorithm types\n",
    "        if hasattr(self.level1_model, 'fit_predict'):\n",
    "            self.level1_labels = self.level1_model.fit_predict(X)\n",
    "        elif hasattr(self.level1_model, 'fit'):\n",
    "            self.level1_model.fit(X)\n",
    "            if hasattr(self.level1_model, 'labels_'):\n",
    "                self.level1_labels = self.level1_model.labels_\n",
    "            elif hasattr(self.level1_model, 'predict'):\n",
    "                self.level1_labels = self.level1_model.predict(X)\n",
    "            else:\n",
    "                raise ValueError(f\"Algorithm {self.level1_config['algorithm']} doesn't support clustering\")\n",
    "\n",
    "    \n",
    "    def _fit_level2(self, X):\n",
    "        \"\"\"Fit Level 2 clustering (sub-clusters within each Level 1 cluster).\"\"\"\n",
    "        n_level1_clusters = len(np.unique(self.level1_labels))\n",
    "        \n",
    "        for level1_id in range(n_level1_clusters):\n",
    "            # Get samples belonging to this Level 1 cluster\n",
    "            mask = self.level1_labels == level1_id\n",
    "            X_subset = X[mask]\n",
    "            \n",
    "            if len(X_subset) < self.min_samples_per_final_cluster:\n",
    "                print(f\"   Level 1 cluster {level1_id}: {len(X_subset)} samples (too few for sub-clustering)\")\n",
    "                self.level2_labels[level1_id] = np.zeros(len(X_subset), dtype=int)\n",
    "                continue\n",
    "            \n",
    "            # Create algorithm for this level\n",
    "            level2_model = self._create_algorithm(self.level2_config)\n",
    "            \n",
    "            # Handle different algorithm types\n",
    "            try:\n",
    "                if hasattr(level2_model, 'fit_predict'):\n",
    "                    level2_labels = level2_model.fit_predict(X_subset)\n",
    "                elif hasattr(level2_model, 'fit'):\n",
    "                    level2_model.fit(X_subset)\n",
    "                    if hasattr(level2_model, 'labels_'):\n",
    "                        level2_labels = level2_model.labels_\n",
    "                    elif hasattr(level2_model, 'predict'):\n",
    "                        level2_labels = level2_model.predict(X_subset)\n",
    "                    else:\n",
    "                        raise ValueError(f\"Algorithm {self.level2_config['algorithm']} doesn't support clustering\")\n",
    "                \n",
    "                self.level2_models[level1_id] = level2_model\n",
    "                self.level2_labels[level1_id] = level2_labels\n",
    "\n",
    "                    \n",
    "            except Exception as e:\n",
    "                print(f\"   Level 1 cluster {level1_id}: Error in sub-clustering - {str(e)}\")\n",
    "                self.level2_labels[level1_id] = np.zeros(len(X_subset), dtype=int)\n",
    "    \n",
    "    def _fit_level3(self, X):\n",
    "        \"\"\"Fit Level 3 clustering (sub-sub-clusters within each Level 2 cluster).\"\"\"\n",
    "        for level1_id in self.level2_labels.keys():\n",
    "            if level1_id not in self.level2_labels:\n",
    "                continue\n",
    "                \n",
    "            level2_labels = self.level2_labels[level1_id]\n",
    "            unique_level2_labels = np.unique(level2_labels)\n",
    "            \n",
    "            for level2_id in unique_level2_labels:\n",
    "                # Get samples belonging to this Level 2 cluster\n",
    "                level1_mask = self.level1_labels == level1_id\n",
    "                level2_mask = level2_labels == level2_id\n",
    "                combined_mask = level1_mask & np.isin(np.arange(len(X)), \n",
    "                                                   np.where(level1_mask)[0][level2_mask])\n",
    "                \n",
    "                X_subset = X[combined_mask]\n",
    "                \n",
    "                if len(X_subset) < self.min_samples_per_final_cluster:\n",
    "                    print(f\"   Level 2 cluster ({level1_id}, {level2_id}): {len(X_subset)} samples (too few for sub-sub-clustering)\")\n",
    "                    self.level3_labels[(level1_id, level2_id)] = np.zeros(len(X_subset), dtype=int)\n",
    "                    continue\n",
    "                \n",
    "                # Create algorithm for this level\n",
    "                level3_model = self._create_algorithm(self.level3_config)\n",
    "                \n",
    "                # Handle different algorithm types\n",
    "                try:\n",
    "                    if hasattr(level3_model, 'fit_predict'):\n",
    "                        level3_labels = level3_model.fit_predict(X_subset)\n",
    "                    elif hasattr(level3_model, 'fit'):\n",
    "                        level3_model.fit(X_subset)\n",
    "                        if hasattr(level3_model, 'labels_'):\n",
    "                            level3_labels = level3_model.labels_\n",
    "                        elif hasattr(level3_model, 'predict'):\n",
    "                            level3_labels = level3_model.predict(X_subset)\n",
    "                        else:\n",
    "                            raise ValueError(f\"Algorithm {self.level3_config['algorithm']} doesn't support clustering\")\n",
    "                    \n",
    "                    self.level3_models[(level1_id, level2_id)] = level3_model\n",
    "                    self.level3_labels[(level1_id, level2_id)] = level3_labels\n",
    "                    \n",
    "\n",
    "                        \n",
    "                except Exception as e:\n",
    "                    print(f\"   Level 2 cluster ({level1_id}, {level2_id}): Error in sub-sub-clustering - {str(e)}\")\n",
    "                    self.level3_labels[(level1_id, level2_id)] = np.zeros(len(X_subset), dtype=int)\n",
    "\n",
    "    def _build_hierarchy(self):\n",
    "        \"\"\"Build the complete hierarchy structure.\"\"\"\n",
    "        self.sample_assignments = []\n",
    "        \n",
    "        for sample_idx in range(self.n_samples):\n",
    "            # Get Level 1 assignment\n",
    "            level1_id = self.level1_labels[sample_idx]\n",
    "            \n",
    "            # Get Level 2 assignment\n",
    "            level1_mask = self.level1_labels == level1_id\n",
    "            level1_indices = np.where(level1_mask)[0]\n",
    "            sample_position_in_level1 = np.where(level1_indices == sample_idx)[0][0]\n",
    "            level2_id = self.level2_labels[level1_id][sample_position_in_level1]\n",
    "            \n",
    "            # Get Level 3 assignment\n",
    "            level2_mask = self.level2_labels[level1_id] == level2_id\n",
    "            level2_indices = np.where(level1_mask)[0][level2_mask]\n",
    "            sample_position_in_level2 = np.where(level2_indices == sample_idx)[0][0]\n",
    "            level3_id = self.level3_labels[(level1_id, level2_id)][sample_position_in_level2]\n",
    "            \n",
    "            assignment = {\n",
    "                'sample_idx': sample_idx,\n",
    "                'sample_name': self.sample_names[sample_idx],\n",
    "                'level1_id': level1_id,\n",
    "                'level2_id': level2_id,\n",
    "                'level3_id': level3_id,\n",
    "                'full_path': f\"{level1_id}_{level2_id}_{level3_id}\"\n",
    "            }\n",
    "            \n",
    "            self.sample_assignments.append(assignment)\n",
    "        \n",
    "        # Build cluster hierarchy\n",
    "        self._build_cluster_hierarchy()\n",
    "    \n",
    "    def _build_cluster_hierarchy(self):\n",
    "        \"\"\"Build the cluster hierarchy structure.\"\"\"\n",
    "        self.cluster_hierarchy = {}\n",
    "        \n",
    "        # Level 1 clusters\n",
    "        for level1_id in range(len(np.unique(self.level1_labels))):\n",
    "            level1_samples = [a for a in self.sample_assignments if a['level1_id'] == level1_id]\n",
    "            \n",
    "            self.cluster_hierarchy[level1_id] = {\n",
    "                'level': 1,\n",
    "                'cluster_id': level1_id,\n",
    "                'sample_count': len(level1_samples),\n",
    "                'samples': level1_samples,\n",
    "                'children': {}\n",
    "            }\n",
    "            \n",
    "            # Level 2 clusters within this Level 1 cluster\n",
    "            unique_level2 = set(a['level2_id'] for a in level1_samples)\n",
    "            for level2_id in unique_level2:\n",
    "                level2_samples = [a for a in level1_samples if a['level2_id'] == level2_id]\n",
    "                \n",
    "                self.cluster_hierarchy[level1_id]['children'][level2_id] = {\n",
    "                    'level': 2,\n",
    "                    'cluster_id': level2_id,\n",
    "                    'sample_count': len(level2_samples),\n",
    "                    'samples': level2_samples,\n",
    "                    'children': {}\n",
    "                }\n",
    "                \n",
    "                # Level 3 clusters within this Level 2 cluster\n",
    "                unique_level3 = set(a['level3_id'] for a in level2_samples)\n",
    "                for level3_id in unique_level3:\n",
    "                    level3_samples = [a for a in level2_samples if a['level3_id'] == level3_id]\n",
    "                    \n",
    "                    self.cluster_hierarchy[level1_id]['children'][level2_id]['children'][level3_id] = {\n",
    "                        'level': 3,\n",
    "                        'cluster_id': level3_id,\n",
    "                        'sample_count': len(level3_samples),\n",
    "                        'samples': level3_samples,\n",
    "                        'children': {}\n",
    "                    }\n",
    "\n",
    "    def _print_hierarchy_summary(self, show_samples=5, original_data=None, feature_names=None, floatfmt=\".2f\"):\n",
    "        \"\"\"\n",
    "        Print a summary of the clustering hierarchy.\n",
    "        For each Level 3 cluster, shows up to `show_samples` samples, each line showing brand, price, and category.\n",
    "        `original_data` should be the original (untouched/untransformed) dataset as a numpy array or pandas DataFrame.\n",
    "        `feature_names` may be optionally provided (for pandas or arrays).\n",
    "        \"\"\"\n",
    "        print(\"\\nüìä HIERARCHY SUMMARY\")\n",
    "        print(\"=\" * 50)\n",
    "        \n",
    "        total_final_clusters = 0\n",
    "\n",
    "        # Use the class's original_data if original_data not provided\n",
    "        if original_data is None:\n",
    "            if self.original_data is None:\n",
    "                raise ValueError(\"original_data (the original features dataset) must be provided to show sample vectors.\")\n",
    "            original_data = self.original_data\n",
    "\n",
    "        # Setup: get indices (column numbers) for 'brand', 'price', 'category'\n",
    "        if hasattr(original_data, \"iloc\"):\n",
    "            original_data_arr = original_data.values\n",
    "            column_names = original_data.columns.tolist() if feature_names is None else feature_names\n",
    "        else:\n",
    "            original_data_arr = np.array(original_data)\n",
    "            column_names = [f\"feat_{i}\" for i in range(original_data.shape[1])] if feature_names is None else feature_names\n",
    "\n",
    "        # Find the indices of 'brand', 'price', and 'category'\n",
    "        def get_feature_idx(name):\n",
    "            try:\n",
    "                return column_names.index(name)\n",
    "            except ValueError:\n",
    "                raise ValueError(f\"Required feature '{name}' not found in column names: {column_names}\")\n",
    "        brand_idx = get_feature_idx('brand')\n",
    "        price_idx = get_feature_idx('price')\n",
    "        category_idx = get_feature_idx('category')\n",
    "        show_indices = [brand_idx, price_idx, category_idx]\n",
    "\n",
    "        for level1_id, level1_data in self.cluster_hierarchy.items():\n",
    "            print(f\"Level 1 Cluster {level1_id}: {level1_data['sample_count']} samples\")\n",
    "            \n",
    "            for level2_id, level2_data in level1_data['children'].items():\n",
    "                print(f\"  Level 2 Cluster {level2_id}: {level2_data['sample_count']} samples\")\n",
    "                \n",
    "                for level3_id, level3_data in level2_data['children'].items():\n",
    "                    sample_indices = [a['sample_idx'] for a in level3_data['samples']]\n",
    "                    sample_count = level3_data['sample_count']\n",
    "                    total_final_clusters += 1\n",
    "                    shown_indices = sample_indices[:show_samples]\n",
    "                    shown_data = original_data_arr[shown_indices]\n",
    "                    print(f\"    Level 3 Cluster {level3_id}: {sample_count} samples\")\n",
    "                    print(f\"      Showing up to {show_samples} samples (brand | price | category):\")\n",
    "                    for row in shown_data:\n",
    "                        to_show = []\n",
    "                        for idx in show_indices:\n",
    "                            v = row[idx]\n",
    "                            # Format price/number if appropriate\n",
    "                            if idx == price_idx:\n",
    "                                try:\n",
    "                                    to_show.append(f\"{float(v):{floatfmt}}\")\n",
    "                                except Exception:\n",
    "                                    to_show.append(str(v))\n",
    "                            else:\n",
    "                                to_show.append(str(v))\n",
    "                        print(f\"        {to_show[0]} | {to_show[1]} | {to_show[2]}\")\n",
    "        \n",
    "        print(f\"\\nüéØ Total final clusters: {total_final_clusters}\")\n",
    "        print(f\"üìà Average samples per final cluster: {self.n_samples / total_final_clusters:.1f}\")\n",
    "    \n",
    "    def get_cluster_path(self, sample_idx):\n",
    "        \"\"\"Get the complete cluster path for a sample.\"\"\"\n",
    "        if sample_idx >= len(self.sample_assignments):\n",
    "            return None\n",
    "        return self.sample_assignments[sample_idx]\n",
    "    \n",
    "    def get_samples_in_cluster(self, level1_id, level2_id=None, level3_id=None):\n",
    "        \"\"\"Get all samples in a specific cluster at any level.\"\"\"\n",
    "        if level2_id is None:\n",
    "            # Level 1 cluster\n",
    "            return [a for a in self.sample_assignments if a['level1_id'] == level1_id]\n",
    "        elif level3_id is None:\n",
    "            # Level 2 cluster\n",
    "            return [a for a in self.sample_assignments \n",
    "                   if a['level1_id'] == level1_id and a['level2_id'] == level2_id]\n",
    "        else:\n",
    "            # Level 3 cluster\n",
    "            return [a for a in self.sample_assignments \n",
    "                   if a['level1_id'] == level1_id and a['level2_id'] == level2_id and a['level3_id'] == level3_id]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "29d1c01b",
   "metadata": {},
   "source": [
    "# Metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "477d6c0f",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import silhouette_score, davies_bouldin_score, calinski_harabasz_score\n",
    "\n",
    "def calculate_silhouette_score_nested(clustering_system, X):\n",
    "    \"\"\"\n",
    "    Calculate Silhouette Score for nested clustering system.\n",
    "    Returns the average Silhouette Score across all levels.\n",
    "    \n",
    "    Args:\n",
    "        clustering_system: FlexibleNestedClusteringSystem instance\n",
    "        X: Feature matrix used for clustering\n",
    "        \n",
    "    Returns:\n",
    "        dict: Dictionary containing scores for each level and average score\n",
    "    \"\"\"\n",
    "    scores = {}\n",
    "    \n",
    "    # Level 1 Silhouette Score\n",
    "    if clustering_system.level1_labels is not None:\n",
    "        try:\n",
    "            level1_score = silhouette_score(X, clustering_system.level1_labels)\n",
    "            scores['level1'] = level1_score\n",
    "            print(f\"Level 1 Silhouette Score: {level1_score:.4f}\")\n",
    "        except Exception as e:\n",
    "            print(f\"Error calculating Level 1 Silhouette Score: {e}\")\n",
    "            scores['level1'] = None\n",
    "    \n",
    "    # Level 2 Silhouette Scores\n",
    "    level2_scores = []\n",
    "    for level1_id in clustering_system.level2_labels.keys():\n",
    "        if clustering_system.level2_labels[level1_id] is not None:\n",
    "            # Get samples belonging to this Level 1 cluster\n",
    "            mask = clustering_system.level1_labels == level1_id\n",
    "            X_subset = X[mask]\n",
    "            level2_labels = clustering_system.level2_labels[level1_id]\n",
    "            \n",
    "            if len(np.unique(level2_labels)) > 1 and len(X_subset) > 1:\n",
    "                try:\n",
    "                    level2_score = silhouette_score(X_subset, level2_labels)\n",
    "                    level2_scores.append(level2_score)\n",
    "                except Exception as e:\n",
    "                    print(f\"Error calculating Level 2 Silhouette Score for cluster {level1_id}: {e}\")\n",
    "    \n",
    "    if level2_scores:\n",
    "        scores['level2'] = np.mean(level2_scores)\n",
    "    else:\n",
    "        scores['level2'] = None\n",
    "    \n",
    "    # Level 3 Silhouette Scores\n",
    "    level3_scores = []\n",
    "    for (level1_id, level2_id) in clustering_system.level3_labels.keys():\n",
    "        if clustering_system.level3_labels[(level1_id, level2_id)] is not None:\n",
    "            # Get samples belonging to this Level 2 cluster\n",
    "            level1_mask = clustering_system.level1_labels == level1_id\n",
    "            level2_mask = clustering_system.level2_labels[level1_id] == level2_id\n",
    "            combined_mask = level1_mask & np.isin(np.arange(len(X)), \n",
    "                                               np.where(level1_mask)[0][level2_mask])\n",
    "            \n",
    "            X_subset = X[combined_mask]\n",
    "            level3_labels = clustering_system.level3_labels[(level1_id, level2_id)]\n",
    "            \n",
    "            if len(np.unique(level3_labels)) > 1 and len(X_subset) > 1:\n",
    "                try:\n",
    "                    level3_score = silhouette_score(X_subset, level3_labels)\n",
    "                    level3_scores.append(level3_score)\n",
    "                except Exception as e:\n",
    "                    print(f\"Error calculating Level 3 Silhouette Score for cluster ({level1_id},{level2_id}): {e}\")\n",
    "    \n",
    "    if level3_scores:\n",
    "        scores['level3'] = np.mean(level3_scores)\n",
    "    else:\n",
    "        scores['level3'] = None\n",
    "    \n",
    "    # Calculate overall average\n",
    "    valid_scores = [score for score in [scores['level1'], scores['level2'], scores['level3']] if score is not None]\n",
    "    if valid_scores:\n",
    "        scores['average'] = np.mean(valid_scores)\n",
    "        print(f\"Overall Average Silhouette: {scores['average']:.4f}\")\n",
    "\n",
    "    else:\n",
    "        scores['average'] = None\n",
    "        print(\"No valid Silhouette Scores calculated\")\n",
    "    \n",
    "    return scores\n",
    "\n",
    "\n",
    "def calculate_davies_bouldin_score_nested(clustering_system, X):\n",
    "    \"\"\"\n",
    "    Calculate Davies-Bouldin Index for nested clustering system.\n",
    "    Returns the average Davies-Bouldin Index across all levels.\n",
    "    Lower values indicate better clustering.\n",
    "    \n",
    "    Args:\n",
    "        clustering_system: FlexibleNestedClusteringSystem instance\n",
    "        X: Feature matrix used for clustering\n",
    "        \n",
    "    Returns:\n",
    "        dict: Dictionary containing scores for each level and average score\n",
    "    \"\"\"\n",
    "    scores = {}\n",
    "    \n",
    "    # Level 1 Davies-Bouldin Score\n",
    "    if clustering_system.level1_labels is not None:\n",
    "        try:\n",
    "            level1_score = davies_bouldin_score(X, clustering_system.level1_labels)\n",
    "            scores['level1'] = level1_score\n",
    "        except Exception as e:\n",
    "            print(f\"Error calculating Level 1 Davies-Bouldin Index: {e}\")\n",
    "            scores['level1'] = None\n",
    "    \n",
    "    # Level 2 Davies-Bouldin Scores\n",
    "    level2_scores = []\n",
    "    for level1_id in clustering_system.level2_labels.keys():\n",
    "        if clustering_system.level2_labels[level1_id] is not None:\n",
    "            # Get samples belonging to this Level 1 cluster\n",
    "            mask = clustering_system.level1_labels == level1_id\n",
    "            X_subset = X[mask]\n",
    "            level2_labels = clustering_system.level2_labels[level1_id]\n",
    "            \n",
    "            if len(np.unique(level2_labels)) > 1 and len(X_subset) > 1:\n",
    "                try:\n",
    "                    level2_score = davies_bouldin_score(X_subset, level2_labels)\n",
    "                    level2_scores.append(level2_score)\n",
    "                except Exception as e:\n",
    "                    print(f\"Error calculating Level 2 Davies-Bouldin Index for cluster {level1_id}: {e}\")\n",
    "    \n",
    "    if level2_scores:\n",
    "        scores['level2'] = np.mean(level2_scores)\n",
    "    else:\n",
    "        scores['level2'] = None\n",
    "    \n",
    "    # Level 3 Davies-Bouldin Scores\n",
    "    level3_scores = []\n",
    "    for (level1_id, level2_id) in clustering_system.level3_labels.keys():\n",
    "        if clustering_system.level3_labels[(level1_id, level2_id)] is not None:\n",
    "            # Get samples belonging to this Level 2 cluster\n",
    "            level1_mask = clustering_system.level1_labels == level1_id\n",
    "            level2_mask = clustering_system.level2_labels[level1_id] == level2_id\n",
    "            combined_mask = level1_mask & np.isin(np.arange(len(X)), \n",
    "                                               np.where(level1_mask)[0][level2_mask])\n",
    "            \n",
    "            X_subset = X[combined_mask]\n",
    "            level3_labels = clustering_system.level3_labels[(level1_id, level2_id)]\n",
    "            \n",
    "            if len(np.unique(level3_labels)) > 1 and len(X_subset) > 1:\n",
    "                try:\n",
    "                    level3_score = davies_bouldin_score(X_subset, level3_labels)\n",
    "                    level3_scores.append(level3_score)\n",
    "                except Exception as e:\n",
    "                    print(f\"Error calculating Level 3 Davies-Bouldin Index for cluster ({level1_id},{level2_id}): {e}\")\n",
    "    \n",
    "    if level3_scores:\n",
    "        scores['level3'] = np.mean(level3_scores)\n",
    "    else:\n",
    "        scores['level3'] = None\n",
    "    \n",
    "    # Calculate overall average\n",
    "    valid_scores = [score for score in [scores['level1'], scores['level2'], scores['level3']] if score is not None]\n",
    "    if valid_scores:\n",
    "        scores['average'] = np.mean(valid_scores)\n",
    "        print(f\"Overall Average Davies-Bouldin Index: {scores['average']:.4f}\")\n",
    "    else:\n",
    "        scores['average'] = None\n",
    "        print(\"No valid Davies-Bouldin Index calculated\")\n",
    "    \n",
    "    return scores\n",
    "\n",
    "\n",
    "def calculate_calinski_harabasz_score_nested(clustering_system, X):\n",
    "    \"\"\"\n",
    "    Calculate Calinski-Harabasz Index for nested clustering system.\n",
    "    Returns the average Calinski-Harabasz Index across all levels.\n",
    "    Higher values indicate better clustering.\n",
    "    \n",
    "    Args:\n",
    "        clustering_system: FlexibleNestedClusteringSystem instance\n",
    "        X: Feature matrix used for clustering\n",
    "        \n",
    "    Returns:\n",
    "        dict: Dictionary containing scores for each level and average score\n",
    "    \"\"\"\n",
    "    scores = {}\n",
    "    \n",
    "    # Level 1 Calinski-Harabasz Score\n",
    "    if clustering_system.level1_labels is not None:\n",
    "        try:\n",
    "            level1_score = calinski_harabasz_score(X, clustering_system.level1_labels)\n",
    "            scores['level1'] = level1_score\n",
    "        except Exception as e:\n",
    "            print(f\"Error calculating Level 1 Calinski-Harabasz Index: {e}\")\n",
    "            scores['level1'] = None\n",
    "    \n",
    "    # Level 2 Calinski-Harabasz Scores\n",
    "    level2_scores = []\n",
    "    for level1_id in clustering_system.level2_labels.keys():\n",
    "        if clustering_system.level2_labels[level1_id] is not None:\n",
    "            # Get samples belonging to this Level 1 cluster\n",
    "            mask = clustering_system.level1_labels == level1_id\n",
    "            X_subset = X[mask]\n",
    "            level2_labels = clustering_system.level2_labels[level1_id]\n",
    "            \n",
    "            if len(np.unique(level2_labels)) > 1 and len(X_subset) > 1:\n",
    "                try:\n",
    "                    level2_score = calinski_harabasz_score(X_subset, level2_labels)\n",
    "                    level2_scores.append(level2_score)\n",
    "                except Exception as e:\n",
    "                    print(f\"Error calculating Level 2 Calinski-Harabasz Index for cluster {level1_id}: {e}\")\n",
    "    \n",
    "    if level2_scores:\n",
    "        scores['level2'] = np.mean(level2_scores)\n",
    "    else:\n",
    "        scores['level2'] = None\n",
    "    \n",
    "    # Level 3 Calinski-Harabasz Scores\n",
    "    level3_scores = []\n",
    "    for (level1_id, level2_id) in clustering_system.level3_labels.keys():\n",
    "        if clustering_system.level3_labels[(level1_id, level2_id)] is not None:\n",
    "            # Get samples belonging to this Level 2 cluster\n",
    "            level1_mask = clustering_system.level1_labels == level1_id\n",
    "            level2_mask = clustering_system.level2_labels[level1_id] == level2_id\n",
    "            combined_mask = level1_mask & np.isin(np.arange(len(X)), \n",
    "                                               np.where(level1_mask)[0][level2_mask])\n",
    "            \n",
    "            X_subset = X[combined_mask]\n",
    "            level3_labels = clustering_system.level3_labels[(level1_id, level2_id)]\n",
    "            \n",
    "            if len(np.unique(level3_labels)) > 1 and len(X_subset) > 1:\n",
    "                try:\n",
    "                    level3_score = calinski_harabasz_score(X_subset, level3_labels)\n",
    "                    level3_scores.append(level3_score)\n",
    "                except Exception as e:\n",
    "                    print(f\"Error calculating Level 3 Calinski-Harabasz Index for cluster ({level1_id},{level2_id}): {e}\")\n",
    "    \n",
    "    if level3_scores:\n",
    "        scores['level3'] = np.mean(level3_scores)\n",
    "    else:\n",
    "        scores['level3'] = None\n",
    "    \n",
    "    # Calculate overall average\n",
    "    valid_scores = [score for score in [scores['level1'], scores['level2'], scores['level3']] if score is not None]\n",
    "    if valid_scores:\n",
    "        scores['average'] = np.mean(valid_scores)\n",
    "        print(f\"Overall Average Calinski-Harabasz Index: {scores['average']:.4f}\")\n",
    "    else:\n",
    "        scores['average'] = None\n",
    "        print(\"No valid Calinski-Harabasz Index calculated\")\n",
    "    \n",
    "    return scores\n",
    "\n",
    "\n",
    "def calculate_all_clustering_metrics(clustering_system, X):\n",
    "    \"\"\"\n",
    "    Calculate all three clustering metrics for the nested clustering system.\n",
    "    \n",
    "    Args:\n",
    "        clustering_system: FlexibleNestedClusteringSystem instance\n",
    "        X: Feature matrix used for clustering\n",
    "        \n",
    "    Returns:\n",
    "        dict: Dictionary containing all metric results\n",
    "    \"\"\"\n",
    "    \n",
    "    results = {}\n",
    "\n",
    "    results['silhouette'] = calculate_silhouette_score_nested(clustering_system, X)\n",
    "\n",
    "    results['davies_bouldin'] = calculate_davies_bouldin_score_nested(clustering_system, X)\n",
    " \n",
    "    results['calinski_harabasz'] = calculate_calinski_harabasz_score_nested(clustering_system, X)\n",
    "    \n",
    "\n",
    "    \n",
    "    # Print summary table\n",
    "    print(f\"{'Metric':<25} {'Level 1':<12} {'Level 2':<12} {'Level 3':<12} {'Average':<12}\")\n",
    "    print(\"-\" * 80)\n",
    "    \n",
    "    metrics = [\n",
    "        ('Silhouette Score', results['silhouette']),\n",
    "        ('Davies-Bouldin Index', results['davies_bouldin']),\n",
    "        ('Calinski-Harabasz Index', results['calinski_harabasz'])\n",
    "    ]\n",
    "    \n",
    "    for metric_name, metric_data in metrics:\n",
    "        level1_val = f\"{metric_data['level1']:.4f}\" if metric_data['level1'] is not None else \"N/A\"\n",
    "        level2_val = f\"{metric_data['level2']:.4f}\" if metric_data['level2'] is not None else \"N/A\"\n",
    "        level3_val = f\"{metric_data['level3']:.4f}\" if metric_data['level3'] is not None else \"N/A\"\n",
    "        avg_val = f\"{metric_data['average']:.4f}\" if metric_data['average'] is not None else \"N/A\"\n",
    "        \n",
    "        print(f\"{metric_name:<25} {level1_val:<12} {level2_val:<12} {level3_val:<12} {avg_val:<12}\")\n",
    "    \n",
    "    return results"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6a0b96c9",
   "metadata": {},
   "source": [
    "# Experiments"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "27c46779",
   "metadata": {},
   "source": [
    "## KMeans"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "ca514dd9",
   "metadata": {},
   "outputs": [],
   "source": [
    "km_description = (\n",
    "    \"This is K-means experiment\"\n",
    ")\n",
    "\n",
    "km_tags = {\n",
    "    \"project_name\": \"stapler_clustering_traditional_ML\",\n",
    "    \"mlflow.note.content\": km_description,\n",
    "}\n",
    "try:\n",
    "    # Get the experiment ID first\n",
    "    experiment = client.get_experiment_by_name(\"K-means\")\n",
    "    if experiment and experiment.lifecycle_stage == 'deleted':\n",
    "        client.restore_experiment(experiment.experiment_id)\n",
    "        print(\"Restored experiment: AgglomerativeClustering\")\n",
    "except Exception as e:\n",
    "    print(f\"Error restoring experiment: {e}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "68d32e0b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Sets the current active experiment to the \"Apple_Models\" experiment and returns the Experiment metadata\n",
    "km_experiment = mlflow.set_experiment(\"K-means\")\n",
    "\n",
    "# Define a run name for this iteration of training.\n",
    "# If this is not set, a unique name will be auto-generated for your run.\n",
    "run_name_km = \"Km\"\n",
    "\n",
    "# Define an artifact path that the model will be saved to.\n",
    "artifact_path = \"km_results\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "5d3eda6c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üîß Starting Flexible Nested Clustering\n",
      "üìä Data shape: (508, 96)\n",
      "üéØ Level 1: KMeans ‚Üí KMeans ‚Üí KMeans\n",
      "============================================================\n",
      "üìç Level 1: KMeans clustering...\n",
      "üìç Level 2: KMeans sub-clustering...\n",
      "üìç Level 3: KMeans sub-sub-clustering...\n",
      "   Level 2 cluster (1, 3): Error in sub-sub-clustering - n_samples=3 should be >= n_clusters=5.\n",
      "   Level 2 cluster (2, 3): 2 samples (too few for sub-sub-clustering)\n",
      "‚úÖ Flexible nested clustering completed!\n",
      "\n",
      "üìä HIERARCHY SUMMARY\n",
      "==================================================\n",
      "Level 1 Cluster 0: 319 samples\n",
      "  Level 2 Cluster 0: 150 samples\n",
      "    Level 3 Cluster 0: 49 samples\n",
      "      Showing up to 5 samples (brand | price | category):\n",
      "        realme | nan | mid\n",
      "        realme | nan | mid\n",
      "        realme | nan | mid\n",
      "        realme | nan | mid\n",
      "        realme | nan | low\n",
      "    Level 3 Cluster 1: 23 samples\n",
      "      Showing up to 5 samples (brand | price | category):\n",
      "        tecno-ma | 150341000.00 | mid\n",
      "        xiaomi | 246990000.00 | mid\n",
      "        xiaomi | 259051000.00 | nan\n",
      "        xiaomi | 248850000.00 | mid\n",
      "        xiaomi | 142900000.00 | nan\n",
      "    Level 3 Cluster 2: 44 samples\n",
      "      Showing up to 5 samples (brand | price | category):\n",
      "        realme | 89266000.00 | low\n",
      "        blackview | 109990000.00 | mid\n",
      "        blackview | 118300000.00 | mid\n",
      "        redtone | 122500000.00 | mid\n",
      "        redtone | 88500000.00 | nan\n",
      "    Level 3 Cluster 3: 18 samples\n",
      "      Showing up to 5 samples (brand | price | category):\n",
      "        xiaomi | nan | mid\n",
      "        tcl | 132990000.00 | mid\n",
      "        samsung | 199000000.00 | mid\n",
      "        samsung | 113238000.00 | low\n",
      "        samsung | 183700000.00 | mid\n",
      "    Level 3 Cluster 4: 16 samples\n",
      "      Showing up to 5 samples (brand | price | category):\n",
      "        xiaomi | 156993000.00 | low\n",
      "        xiaomi | 179990000.00 | mid\n",
      "        xiaomi | 177990000.00 | mid\n",
      "        honor | 288186000.00 | mid\n",
      "        samsung | 240832000.00 | low\n",
      "  Level 2 Cluster 1: 65 samples\n",
      "    Level 3 Cluster 0: 5 samples\n",
      "      Showing up to 5 samples (brand | price | category):\n",
      "        daria | nan | mid\n",
      "        daria | 138548000.00 | mid\n",
      "        daria | 126990000.00 | mid\n",
      "        daria | 119990000.00 | mid\n",
      "        daria | 134500000.00 | mid\n",
      "    Level 3 Cluster 1: 35 samples\n",
      "      Showing up to 5 samples (brand | price | category):\n",
      "        apple | nan | high\n",
      "        apple | nan | mid\n",
      "        apple | nan | high\n",
      "        apple | nan | high\n",
      "        apple | nan | high\n",
      "    Level 3 Cluster 2: 15 samples\n",
      "      Showing up to 5 samples (brand | price | category):\n",
      "        realme | nan | nan\n",
      "        realme | nan | nan\n",
      "        realme | nan | nan\n",
      "        oneplus | nan | nan\n",
      "        oneplus | nan | mid\n",
      "    Level 3 Cluster 3: 8 samples\n",
      "      Showing up to 5 samples (brand | price | category):\n",
      "        blackview | nan | low\n",
      "        nothing | nan | nan\n",
      "        nothing | nan | nan\n",
      "        nothing | nan | nan\n",
      "        tcl | nan | mid\n",
      "    Level 3 Cluster 4: 2 samples\n",
      "      Showing up to 5 samples (brand | price | category):\n",
      "        realme | nan | nan\n",
      "        realme | nan | nan\n",
      "  Level 2 Cluster 2: 14 samples\n",
      "    Level 3 Cluster 0: 2 samples\n",
      "      Showing up to 5 samples (brand | price | category):\n",
      "        xiaomi | 209000000.00 | mid\n",
      "        samsung | nan | mid\n",
      "    Level 3 Cluster 1: 5 samples\n",
      "      Showing up to 5 samples (brand | price | category):\n",
      "        daria | 110990000.00 | mid\n",
      "        xiaomi | 174950000.00 | mid\n",
      "        xiaomi | 190000000.00 | mid\n",
      "        xiaomi | 307000000.00 | mid\n",
      "        samsung | nan | mid\n",
      "    Level 3 Cluster 2: 1 samples\n",
      "      Showing up to 5 samples (brand | price | category):\n",
      "        apple | 814000000.00 | high\n",
      "    Level 3 Cluster 3: 5 samples\n",
      "      Showing up to 5 samples (brand | price | category):\n",
      "        samsung | 325000000.00 | mid\n",
      "        samsung | 1315000000.00 | high\n",
      "        samsung | 509990000.00 | mid\n",
      "        samsung | 406000000.00 | mid\n",
      "        samsung | 283966000.00 | mid\n",
      "    Level 3 Cluster 4: 1 samples\n",
      "      Showing up to 5 samples (brand | price | category):\n",
      "        apple | 1540000000.00 | high\n",
      "  Level 2 Cluster 3: 90 samples\n",
      "    Level 3 Cluster 0: 9 samples\n",
      "      Showing up to 5 samples (brand | price | category):\n",
      "        apple | 1020000000.00 | high\n",
      "        apple | 2729980000.00 | high\n",
      "        apple | 1838990000.00 | high\n",
      "        apple | 2040000000.00 | high\n",
      "        apple | 1044990000.00 | high\n",
      "    Level 3 Cluster 1: 41 samples\n",
      "      Showing up to 5 samples (brand | price | category):\n",
      "        realme | 227990000.00 | high\n",
      "        realme | 254490000.00 | high\n",
      "        nothing | 529990000.00 | nan\n",
      "        nothing | 194373000.00 | mid\n",
      "        nothing | 968057000.00 | high\n",
      "    Level 3 Cluster 2: 9 samples\n",
      "      Showing up to 5 samples (brand | price | category):\n",
      "        apple | 1017990000.00 | high\n",
      "        xiaomi | 768000000.00 | mid\n",
      "        xiaomi | 815700000.00 | mid\n",
      "        xiaomi | 519990000.00 | mid\n",
      "        samsung | 579990000.00 | mid\n",
      "    Level 3 Cluster 3: 20 samples\n",
      "      Showing up to 5 samples (brand | price | category):\n",
      "        nothing | 319490000.00 | high\n",
      "        xiaomi | 383990000.00 | mid\n",
      "        xiaomi | 356990000.00 | mid\n",
      "        motorola | 269900000.00 | high\n",
      "        honor | 313990000.00 | mid\n",
      "    Level 3 Cluster 4: 11 samples\n",
      "      Showing up to 5 samples (brand | price | category):\n",
      "        xiaomi | 1299900000.00 | nan\n",
      "        xiaomi | 609990000.00 | mid\n",
      "        oneplus | 911290000.00 | high\n",
      "        samsung | 2100000000.00 | high\n",
      "        samsung | 1370637000.00 | high\n",
      "Level 1 Cluster 1: 87 samples\n",
      "  Level 2 Cluster 0: 41 samples\n",
      "    Level 3 Cluster 0: 10 samples\n",
      "      Showing up to 5 samples (brand | price | category):\n",
      "        blackview | nan | low\n",
      "        blackview | nan | low\n",
      "        blackview | nan | low\n",
      "        blackview | nan | low\n",
      "        blackview | nan | mid\n",
      "    Level 3 Cluster 1: 19 samples\n",
      "      Showing up to 5 samples (brand | price | category):\n",
      "        realme | 100100000.00 | low\n",
      "        realme | nan | low\n",
      "        realme | 93000000.00 | low\n",
      "        realme | 117950000.00 | low\n",
      "        realme | 108000000.00 | mid\n",
      "    Level 3 Cluster 2: 6 samples\n",
      "      Showing up to 5 samples (brand | price | category):\n",
      "        blackview | nan | nan\n",
      "        ruggear | nan | nan\n",
      "        honor | nan | nan\n",
      "        honor | nan | nan\n",
      "        samsung | 93990000.00 | nan\n",
      "    Level 3 Cluster 3: 1 samples\n",
      "      Showing up to 5 samples (brand | price | category):\n",
      "        blackberry | nan | nan\n",
      "    Level 3 Cluster 4: 5 samples\n",
      "      Showing up to 5 samples (brand | price | category):\n",
      "        general-luxe-it | 65094000.00 | low\n",
      "        tch | 89990000.00 | low\n",
      "        tch | 79990000.00 | low\n",
      "        tcl | nan | low\n",
      "        motorola | 82990000.00 | mid\n",
      "  Level 2 Cluster 1: 30 samples\n",
      "    Level 3 Cluster 0: 6 samples\n",
      "      Showing up to 5 samples (brand | price | category):\n",
      "        blackberry | nan | nan\n",
      "        blackberry | nan | nan\n",
      "        blackberry | nan | nan\n",
      "        blackberry | nan | nan\n",
      "        blackberry | nan | nan\n",
      "    Level 3 Cluster 1: 8 samples\n",
      "      Showing up to 5 samples (brand | price | category):\n",
      "        glx | nan | nan\n",
      "        miscellaneous | nan | nan\n",
      "        alcatel | nan | nan\n",
      "        alcatel | nan | nan\n",
      "        alcatel | nan | nan\n",
      "    Level 3 Cluster 2: 4 samples\n",
      "      Showing up to 5 samples (brand | price | category):\n",
      "        ruggear | 57000000.00 | low\n",
      "        hanofer-mo | 31490000.00 | low\n",
      "        miscellaneous | nan | nan\n",
      "        blackberry | nan | nan\n",
      "    Level 3 Cluster 3: 1 samples\n",
      "      Showing up to 5 samples (brand | price | category):\n",
      "        tcl | nan | mid\n",
      "    Level 3 Cluster 4: 11 samples\n",
      "      Showing up to 5 samples (brand | price | category):\n",
      "        ruggear | nan | nan\n",
      "        glx | nan | nan\n",
      "        tcl | nan | low\n",
      "        tcl | nan | low\n",
      "        miscellaneous | nan | nan\n",
      "  Level 2 Cluster 2: 13 samples\n",
      "    Level 3 Cluster 0: 1 samples\n",
      "      Showing up to 5 samples (brand | price | category):\n",
      "        apple | nan | high\n",
      "    Level 3 Cluster 1: 8 samples\n",
      "      Showing up to 5 samples (brand | price | category):\n",
      "        dox | nan | nan\n",
      "        blackberry | nan | nan\n",
      "        blackberry | nan | nan\n",
      "        blackberry | nan | nan\n",
      "        blackberry | nan | nan\n",
      "    Level 3 Cluster 2: 2 samples\n",
      "      Showing up to 5 samples (brand | price | category):\n",
      "        apple | 769990000.00 | high\n",
      "        apple | 804900000.00 | high\n",
      "    Level 3 Cluster 3: 1 samples\n",
      "      Showing up to 5 samples (brand | price | category):\n",
      "        blackberry | nan | nan\n",
      "    Level 3 Cluster 4: 1 samples\n",
      "      Showing up to 5 samples (brand | price | category):\n",
      "        xiaomi | 92000000.00 | low\n",
      "  Level 2 Cluster 3: 3 samples\n",
      "    Level 3 Cluster 0: 3 samples\n",
      "      Showing up to 5 samples (brand | price | category):\n",
      "        oneplus | nan | nan\n",
      "        oneplus | nan | high\n",
      "        oneplus | nan | mid\n",
      "Level 1 Cluster 2: 102 samples\n",
      "  Level 2 Cluster 0: 11 samples\n",
      "    Level 3 Cluster 0: 1 samples\n",
      "      Showing up to 5 samples (brand | price | category):\n",
      "        glx | nan | nan\n",
      "    Level 3 Cluster 1: 1 samples\n",
      "      Showing up to 5 samples (brand | price | category):\n",
      "        glx | nan | nan\n",
      "    Level 3 Cluster 2: 4 samples\n",
      "      Showing up to 5 samples (brand | price | category):\n",
      "        other | 10450000.00 | low\n",
      "        miscellaneous | nan | low\n",
      "        miscellaneous | nan | low\n",
      "        miscellaneous | nan | low\n",
      "    Level 3 Cluster 3: 2 samples\n",
      "      Showing up to 5 samples (brand | price | category):\n",
      "        miscellaneous | nan | low\n",
      "        miscellaneous | nan | low\n",
      "    Level 3 Cluster 4: 3 samples\n",
      "      Showing up to 5 samples (brand | price | category):\n",
      "        tch | 12790000.00 | low\n",
      "        tch | 26990000.00 | low\n",
      "        tch | 13690000.00 | low\n",
      "  Level 2 Cluster 1: 38 samples\n",
      "    Level 3 Cluster 0: 6 samples\n",
      "      Showing up to 5 samples (brand | price | category):\n",
      "        dox | nan | nan\n",
      "        dox | nan | low\n",
      "        dox | 17790000.00 | nan\n",
      "        dox | nan | nan\n",
      "        miscellaneous | nan | nan\n",
      "    Level 3 Cluster 1: 8 samples\n",
      "      Showing up to 5 samples (brand | price | category):\n",
      "        hanofer-mo | 20950000.00 | low\n",
      "        hanofer-mo | 14650000.00 | low\n",
      "        hanofer-mo | 20350000.00 | low\n",
      "        hanofer-mo | 20100000.00 | low\n",
      "        hanofer-mo | 19700000.00 | low\n",
      "    Level 3 Cluster 2: 3 samples\n",
      "      Showing up to 5 samples (brand | price | category):\n",
      "        ruggear | nan | nan\n",
      "        glx | nan | nan\n",
      "        nokia | nan | low\n",
      "    Level 3 Cluster 3: 16 samples\n",
      "      Showing up to 5 samples (brand | price | category):\n",
      "        hanofer-mo | 11000000.00 | low\n",
      "        hanofer-mo | 10190000.00 | low\n",
      "        hanofer-mo | 12690000.00 | low\n",
      "        hanofer-mo | 16480300.00 | low\n",
      "        hanofer-mo | 12550000.00 | low\n",
      "    Level 3 Cluster 4: 5 samples\n",
      "      Showing up to 5 samples (brand | price | category):\n",
      "        hanofer-mo | 14450000.00 | low\n",
      "        hanofer-mo | 10100000.00 | low\n",
      "        hanofer-mo | 6990000.00 | low\n",
      "        hanofer-mo | 9850000.00 | low\n",
      "        hanofer-mo | 10190000.00 | nan\n",
      "  Level 2 Cluster 2: 51 samples\n",
      "    Level 3 Cluster 0: 7 samples\n",
      "      Showing up to 5 samples (brand | price | category):\n",
      "        glx | 29290000.00 | low\n",
      "        hanofer-mo | 13570300.00 | low\n",
      "        hanofer-mo | 21550000.00 | low\n",
      "        miscellaneous | 9890000.00 | low\n",
      "        miscellaneous | nan | low\n",
      "    Level 3 Cluster 1: 8 samples\n",
      "      Showing up to 5 samples (brand | price | category):\n",
      "        general-luxe-it | 20250000.00 | low\n",
      "        general-luxe-it | 19750000.00 | low\n",
      "        miscellaneous | nan | nan\n",
      "        alcatel | nan | nan\n",
      "        alcatel | nan | nan\n",
      "    Level 3 Cluster 2: 10 samples\n",
      "      Showing up to 5 samples (brand | price | category):\n",
      "        glx | nan | low\n",
      "        other | 8490000.00 | low\n",
      "        other | 9190000.00 | low\n",
      "        nokia | 28900000.00 | low\n",
      "        nokia | 33400000.00 | low\n",
      "    Level 3 Cluster 3: 24 samples\n",
      "      Showing up to 5 samples (brand | price | category):\n",
      "        general-luxe-it | 16720000.00 | low\n",
      "        general-luxe-it | 12310000.00 | nan\n",
      "        general-luxe-it | 13950000.00 | nan\n",
      "        other | 13390000.00 | low\n",
      "        glx | 12240000.00 | low\n",
      "    Level 3 Cluster 4: 2 samples\n",
      "      Showing up to 5 samples (brand | price | category):\n",
      "        nokia | 74990000.00 | nan\n",
      "        nokia | nan | nan\n",
      "  Level 2 Cluster 3: 2 samples\n",
      "    Level 3 Cluster 0: 2 samples\n",
      "      Showing up to 5 samples (brand | price | category):\n",
      "        glx | nan | low\n",
      "        dox | nan | low\n",
      "\n",
      "üéØ Total final clusters: 52\n",
      "üìà Average samples per final cluster: 9.8\n",
      "Level 1 Silhouette Score: 0.3804\n",
      "Overall Average Silhouette: 0.2931\n",
      "Overall Average Davies-Bouldin Index: 1.1866\n",
      "Overall Average Calinski-Harabasz Index: 237.0126\n",
      "Metric                    Level 1      Level 2      Level 3      Average     \n",
      "--------------------------------------------------------------------------------\n",
      "Silhouette Score          0.3804       0.3059       0.1930       0.2931      \n",
      "Davies-Bouldin Index      1.0131       1.2464       1.3003       1.1866      \n",
      "Calinski-Harabasz Index   627.7980     72.6207      10.6192      237.0126    \n",
      "Level 1 Silhouette Score: 0.3804\n",
      "Overall Average Silhouette: 0.2931\n",
      "Overall Average Davies-Bouldin Index: 1.1866\n",
      "Overall Average Calinski-Harabasz Index: 237.0126\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/media/alireza/2ADF0001DEFFC2DD/KASEB/.venv/lib/python3.13/site-packages/mlflow/types/utils.py:452: UserWarning: Hint: Inferred schema contains integer column(s). Integer columns in Python cannot represent missing values. If your input data contains missing values at inference time, it will be encoded as floats and will cause a schema enforcement error. The best way to avoid this problem is to infer the model schema based on a realistic data sample (training dataset) that includes missing values. Alternatively, you can declare integer columns as doubles (float64) whenever these columns may have missing values. See `Handling Integers With Missing Values <https://www.mlflow.org/docs/latest/models.html#handling-integers-with-missing-values>`_ for more details.\n",
      "  warnings.warn(\n",
      "2025/10/29 18:17:47 WARNING mlflow.models.signature: Failed to infer the model signature from the input example. Reason: MlflowException(\"Failed to enforce schema of data '               brand category        price       rate  count_raters  \\\\\\n0    general-luxe-it      low   16720000.0  76.712329           146   \\n50         blackview      mid          NaN  71.428571            14   \\n100              glx      NaN          NaN  60.000000             1   \\n150            daria      mid  126990000.0  89.189189           111   \\n200           xiaomi      mid          NaN  92.687225           227   \\n250         motorola      mid  442839000.0  91.428571            28   \\n300       hmd-mobile      mid          NaN  75.000000             4   \\n350          alcatel      NaN          NaN  80.000000             1   \\n400          samsung      mid  266408000.0  88.468468           333   \\n450          samsung      mid  275990000.0  84.444444            54   \\n500            vocal      low          NaN  84.592593           270   \\n\\n     popularity  num_questions  num_comments  suggestions_count  \\\\\\n0             2             35           103               50.0   \\n50            0             17            22                0.0   \\n100           0              0             1                0.0   \\n150           4             95           101                0.0   \\n200           4            279           189                0.0   \\n250           3             18            28                0.0   \\n300           1              8             6                0.0   \\n350           0              0            11                0.0   \\n400           5             85           209                0.0   \\n450           3             12            39                0.0   \\n500           2            250           218               30.0   \\n\\n     suggestions_percentage  ...        video battery_power_mah  \\\\\\n0                      72.0  ...          NaN            1020.0   \\n50                    100.0  ...  1440p@30FPS            5050.0   \\n100                   100.0  ...          NaN               NaN   \\n150                   100.0  ...     4K@30FPS            4700.0   \\n200                   100.0  ...     8K@24FPS            5000.0   \\n250                     0.0  ...     4K@30FPS            5000.0   \\n300                     0.0  ...          NaN            5000.0   \\n350                   100.0  ...  1080p@30FPS            2500.0   \\n400                   100.0  ...     4K@30FPS            5000.0   \\n450                     0.0  ...     4K@30FPS            5000.0   \\n500                    82.0  ...  720p@480FPS            5000.0   \\n\\n     selfie_resolution_mp cpu_cats engagement_level  thickness      volume  \\\\\\n0                     NaN        5              low      15.00   97.500000   \\n50                    NaN        4         very_low       8.60  102.666112   \\n100                   NaN        5         very_low      13.20   74.382000   \\n150                   NaN        1              low       8.00   96.496000   \\n200                   NaN        2           medium       8.20   98.953500   \\n250                  32.0        2              low       7.80   90.806976   \\n300                   8.0        1         very_low       8.45  103.449242   \\n350                   NaN        1         very_low       7.90   76.642956   \\n400                  13.0        3           medium       7.70   97.867000   \\n450                  13.0        3              low       7.70   97.867000   \\n500                   NaN        1              low       8.55  104.673493   \\n\\n      density all_pixels  price_cat  \\n0    0.923077        NaN          0  \\n50   1.909101    2634.65        NaN  \\n100  1.384744        NaN        NaN  \\n150  2.176256        NaN          2  \\n200  2.112103    3508.42        NaN  \\n250  1.982227    2988.20          5  \\n300  1.807650    1738.40        NaN  \\n350  1.630939    2205.00        NaN  \\n400  2.043590    2579.50          4  \\n450  2.043590    2579.50          4  \\n500       NaN        NaN        NaN  \\n\\n[11 rows x 34 columns]' with schema '['brand': string (required), 'category': string (optional), 'price': double (optional), 'rate': double (required), 'count_raters': long (required), 'popularity': long (required), 'num_questions': long (required), 'num_comments': long (required), 'suggestions_count': double (required), 'suggestions_percentage': double (required), 'os': string (optional), 'introduce_date': string (required), 'weight': double (optional), 'display_technology': string (optional), 'refresh_rate': string (optional), 'size_screen_inch': double (required), 'display_to_body_ratio': string (optional), 'pixel_per_inch': double (optional), 'cpu_model': string (optional), 'storage_gb': double (optional), 'ram_gb': double (optional), 'internet': string (required), 'camera_num': double (optional), 'camera_resolution_mp': double (optional), 'video': string (optional), 'battery_power_mah': double (optional), 'selfie_resolution_mp': double (optional), 'cpu_cats': integer (required), 'engagement_level': string (required), 'thickness': double (required), 'volume': double (required), 'density': double (optional), 'all_pixels': double (optional), 'price_cat': string (optional)]'. Error: Incompatible input types for column refresh_rate. Can not safely convert category to <U0.\"). To see the full traceback, set the logging level to DEBUG via `logging.getLogger(\"mlflow\").setLevel(logging.DEBUG)`.\n",
      "2025/10/29 18:17:47 WARNING mlflow.sklearn: Model was missing function: predict. Not logging python_function flavor!\n",
      "2025/10/29 18:17:50 WARNING mlflow.utils.environment: Failed to resolve installed pip version. ``pip`` will be added to conda.yaml environment spec without a version specifier.\n",
      "2025/10/29 18:17:50 WARNING mlflow.models.model: Failed to validate serving input example {\n",
      "  \"dataframe_split\": {\n",
      "    \"columns\": [\n",
      "      \"b.... Alternatively, you can avoid passing input example and pass model signature instead when logging the model. To ensure the input example is valid prior to serving, please try calling `mlflow.models.validate_serving_input` on the model uri and serving input example. A serving input example can be generated from model input example using `mlflow.models.convert_input_example_to_serving_input` function.\n",
      "Got error: Model does not have the \"python_function\" flavor\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üèÉ View run Km at: http://127.0.0.1:8080/#/experiments/694982361173019963/runs/21e0830d6fe1455396a7a0cf3da2b06b\n",
      "üß™ View experiment at: http://127.0.0.1:8080/#/experiments/694982361173019963\n"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "# Create a second configuration with different algorithms\n",
    "level1_config_2 = {\n",
    "    'algorithm': 'KMeans',\n",
    "    'n_clusters': 3,\n",
    "}\n",
    "\n",
    "level2_config_2 = {\n",
    "    'algorithm': 'KMeans',\n",
    "    'n_clusters': 4,\n",
    "}\n",
    "\n",
    "level3_config_2 = {\n",
    "    'algorithm': 'KMeans',\n",
    "    'n_clusters': 5,\n",
    "\n",
    "}\n",
    "params = {\n",
    "    \"level1_config\" : level1_config_2,\n",
    "    \"level2_config\" : level2_config_2,\n",
    "    \"level3_config\" : level3_config_2\n",
    "\n",
    "}\n",
    "# Create second flexible clustering system\n",
    "flexible_clustering_2 = FlexibleNestedClusteringSystem(\n",
    "    level1_config=level1_config_2,\n",
    "    level2_config=level2_config_2,\n",
    "    level3_config=level3_config_2,\n",
    "    min_samples_per_final_cluster=3,\n",
    "    original_data=mobile\n",
    ")\n",
    "\n",
    "# Fit on your transformed data\n",
    "sample_names = [f\"Mobile_{i}\" for i in range(len(transformed))] #TODO is it necessary ?\n",
    "\n",
    "tfd = transformed.copy()\n",
    "flexible_clustering_2.fit(tfd, sample_names)\n",
    "\n",
    "\n",
    "\n",
    "# Calculate all metrics\n",
    "metrics_results = calculate_all_clustering_metrics(flexible_clustering_2, transformed)\n",
    "\n",
    "# Or calculate individual metrics\n",
    "silhouette_scores = calculate_silhouette_score_nested(flexible_clustering_2, transformed)\n",
    "davies_bouldin_scores = calculate_davies_bouldin_score_nested(flexible_clustering_2, transformed)\n",
    "calinski_harabasz_scores = calculate_calinski_harabasz_score_nested(flexible_clustering_2, transformed)\n",
    "\n",
    "metrics = {\n",
    "    \"Silhouette Score\": silhouette_scores['average'],\n",
    "    \"Davies-Bouldin Index\": davies_bouldin_scores['average'],\n",
    "    \"Calinski-Harabasz Index\": calinski_harabasz_scores['average']\n",
    "}\n",
    "\n",
    "with mlflow.start_run(run_name=run_name_km):\n",
    "\n",
    "    mlflow.log_params(params)\n",
    "\n",
    "    mlflow.log_metrics(metrics)\n",
    "\n",
    "    mlflow.sklearn.log_model(sk_model=flexible_clustering_2,input_example=mobile[::50],name=artifact_path)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7c9de5ef",
   "metadata": {},
   "source": [
    "# Linkage"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "1c0bd636",
   "metadata": {},
   "outputs": [],
   "source": [
    "link_description = (\n",
    "    \"This is Linkage experiment\"\n",
    ")\n",
    "\n",
    "link_tags = {\n",
    "    \"project_name\": \"stapler_clustering_traditional_ML\",\n",
    "    \"mlflow.note.content\": link_description,\n",
    "}\n",
    "try:\n",
    "    # Get the experiment ID first\n",
    "    experiment = client.get_experiment_by_name(\"Link\")\n",
    "    if experiment and experiment.lifecycle_stage == 'deleted':\n",
    "        client.restore_experiment(experiment.experiment_id)\n",
    "        print(\"Restored experiment: Link\")\n",
    "except Exception as e:\n",
    "    print(f\"Error restoring experiment: {e}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "48435bb3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Sets the current active experiment to the \"Apple_Models\" experiment and returns the Experiment metadata\n",
    "link_experiment = mlflow.set_experiment(\"Link\")\n",
    "\n",
    "# Define a run name for this iteration of training.\n",
    "# If this is not set, a unique name will be auto-generated for your run.\n",
    "run_name_link = \"link_first\"\n",
    "\n",
    "# Define an artifact path that the model will be saved to.\n",
    "artifact_path = \"link_results\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "6da47d3c",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "from scipy.cluster.hierarchy import linkage, dendrogram, fcluster\n",
    "from scipy.spatial.distance import pdist\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "\n",
    "class FixedSingleModelHierarchicalClustering(BaseEstimator,ClusterMixin):\n",
    "    \"\"\"\n",
    "    Fixed Single Model Hierarchical Clustering System that uses one hierarchical clustering model\n",
    "    and saves the merging process to extract subclusters and sub-subclusters.\n",
    "    \"\"\"\n",
    "    \n",
    "    def __init__(self, \n",
    "                 n_level1_clusters: int = 5,\n",
    "                 n_level2_clusters: int = 3, \n",
    "                 n_level3_clusters: int = 2,\n",
    "                 linkage_method: str = 'ward',\n",
    "                 min_samples_per_final_cluster: int = 3,\n",
    "                 original_data=None):\n",
    "        \"\"\"\n",
    "        Initialize single model hierarchical clustering system.\n",
    "\n",
    "        Args:\n",
    "            n_level1_clusters: Number of top-level clusters\n",
    "            n_level2_clusters: Number of sub-clusters within each Level 1 cluster\n",
    "            n_level3_clusters: Number of sub-sub-clusters within each Level 2 cluster\n",
    "            linkage_method: Linkage method for hierarchical clustering ('ward', 'complete', 'average', 'single')\n",
    "            min_samples_per_final_cluster: Minimum samples in final clusters\n",
    "            original_data: The original (untransformed) data (optional, used for reporting only)\n",
    "        \"\"\"\n",
    "        self.n_level1_clusters = n_level1_clusters\n",
    "        self.n_level2_clusters = n_level2_clusters\n",
    "        self.n_level3_clusters = n_level3_clusters\n",
    "        self.linkage_method = linkage_method\n",
    "        self.min_samples_per_final_cluster = min_samples_per_final_cluster\n",
    "        \n",
    "        # Store the original data, used for summary/visualization only\n",
    "        self.original_data = original_data\n",
    "        \n",
    "        # Storage for models and results\n",
    "        self.linkage_matrix = None\n",
    "        self.level1_labels = None\n",
    "        self.level2_labels = {}\n",
    "        self.level3_labels = {}\n",
    "        self.sample_assignments = None\n",
    "        self.cluster_hierarchy = {}\n",
    "        self.sample_names = None\n",
    "        self.n_samples = 0\n",
    "        self.X_data = None  # Store original data for sub-clustering\n",
    "    \n",
    "    def fit(self, X, sample_names=None):\n",
    "        \"\"\"\n",
    "        Fit the hierarchical clustering model and extract multi-level clusters.\n",
    "        \n",
    "        Args:\n",
    "            X: Feature matrix\n",
    "            sample_names: Optional names for samples\n",
    "        \"\"\"\n",
    "        if sample_names is None:\n",
    "            sample_names = [f\"Sample_{i}\" for i in range(len(X))]\n",
    "        \n",
    "        self.sample_names = sample_names\n",
    "        self.n_samples = len(X)\n",
    "        self.X_data = X  # Store the original data for sub-clustering\n",
    "        \n",
    "        print(\"üå≥ Starting Fixed Single Model Hierarchical Clustering\")\n",
    "        print(f\"üìä Data shape: {X.shape}\")\n",
    "        print(f\"üéØ Target clusters: Level 1={self.n_level1_clusters}, Level 2={self.n_level2_clusters}, Level 3={self.n_level3_clusters}\")\n",
    "        print(f\"üîó Linkage method: {self.linkage_method}\")\n",
    "        print(\"=\" * 60)\n",
    "        \n",
    "        # Step 1: Create linkage matrix (this saves the merging process)\n",
    "        print(\"üìç Step 1: Creating linkage matrix...\")\n",
    "        self._create_linkage_matrix(X)\n",
    "        \n",
    "        # Step 2: Extract Level 1 clusters\n",
    "        print(\"üìç Step 2: Extracting Level 1 clusters...\")\n",
    "        self._extract_level1_clusters()\n",
    "        \n",
    "        # Step 3: Extract Level 2 clusters\n",
    "        print(\"üìç Step 3: Extracting Level 2 clusters...\")\n",
    "        self._extract_level2_clusters()\n",
    "        \n",
    "        # Step 4: Extract Level 3 clusters\n",
    "        print(\"üìç Step 4: Extracting Level 3 clusters...\")\n",
    "        self._extract_level3_clusters()\n",
    "        \n",
    "        # Step 5: Build hierarchy\n",
    "        print(\"üìç Step 5: Building hierarchy...\")\n",
    "        self._build_hierarchy()\n",
    "        \n",
    "        print(\"‚úÖ Fixed single model hierarchical clustering completed!\")\n",
    "        self._print_hierarchy_summary(original_data=self.original_data)\n",
    "        \n",
    "        return self\n",
    "    \n",
    "    def _create_linkage_matrix(self, X):\n",
    "        \"\"\"Create linkage matrix using hierarchical clustering.\"\"\"\n",
    "        # Calculate pairwise distances\n",
    "        distances = pdist(X, metric='euclidean')\n",
    "        \n",
    "        # Create linkage matrix\n",
    "        self.linkage_matrix = linkage(distances, method=self.linkage_method)\n",
    "        \n",
    "        print(f\"   Linkage matrix shape: {self.linkage_matrix.shape}\")\n",
    "    \n",
    "    def _extract_level1_clusters(self):\n",
    "        \"\"\"Extract Level 1 clusters from linkage matrix.\"\"\"\n",
    "        # Use fcluster to get Level 1 clusters\n",
    "        self.level1_labels = fcluster(self.linkage_matrix, \n",
    "                                     t=self.n_level1_clusters, \n",
    "                                     criterion='maxclust') - 1  # Convert to 0-based indexing\n",
    "        \n",
    "        # Print Level 1 results\n",
    "        unique_labels, counts = np.unique(self.level1_labels, return_counts=True)\n",
    "        print(f\"   Level 1 clusters: {len(unique_labels)}\")\n",
    "        for label, count in zip(unique_labels, counts):\n",
    "            print(f\"     Cluster {label}: {count} samples\")\n",
    "    \n",
    "    def _extract_level2_clusters(self):\n",
    "        \"\"\"Extract Level 2 clusters for each Level 1 cluster.\"\"\"\n",
    "        n_level1_clusters = len(np.unique(self.level1_labels))\n",
    "        \n",
    "        for level1_id in range(n_level1_clusters):\n",
    "            # Get samples belonging to this Level 1 cluster\n",
    "            mask = self.level1_labels == level1_id\n",
    "            level1_indices = np.where(mask)[0]\n",
    "            \n",
    "            if len(level1_indices) < self.min_samples_per_final_cluster:\n",
    "                print(f\"   Level 1 cluster {level1_id}: {len(level1_indices)} samples (too few for sub-clustering)\")\n",
    "                self.level2_labels[level1_id] = np.zeros(len(level1_indices), dtype=int)\n",
    "                continue\n",
    "            \n",
    "            # Create sub-linkage matrix for this Level 1 cluster\n",
    "            sub_linkage = self._create_sub_linkage_matrix(level1_indices, self.X_data)\n",
    "            \n",
    "            if sub_linkage is not None:\n",
    "                # Extract Level 2 clusters\n",
    "                level2_labels = fcluster(sub_linkage, \n",
    "                                       t=self.n_level2_clusters, \n",
    "                                       criterion='maxclust') - 1\n",
    "                \n",
    "                self.level2_labels[level1_id] = level2_labels\n",
    "                \n",
    "                # Print Level 2 results\n",
    "                unique_labels, counts = np.unique(level2_labels, return_counts=True)\n",
    "                print(f\"   Level 1 cluster {level1_id}: {len(level1_indices)} samples ‚Üí {len(unique_labels)} sub-clusters\")\n",
    "                for sub_label, count in zip(unique_labels, counts):\n",
    "                    print(f\"     Sub-cluster {sub_label}: {count} samples\")\n",
    "            else:\n",
    "                print(f\"   Level 1 cluster {level1_id}: Could not create sub-linkage matrix\")\n",
    "                self.level2_labels[level1_id] = np.zeros(len(level1_indices), dtype=int)\n",
    "    \n",
    "    def _extract_level3_clusters(self):\n",
    "        \"\"\"Extract Level 3 clusters for each Level 2 cluster.\"\"\"\n",
    "        for level1_id in self.level2_labels.keys():\n",
    "            if level1_id not in self.level2_labels:\n",
    "                continue\n",
    "                \n",
    "            level2_labels = self.level2_labels[level1_id]\n",
    "            unique_level2_labels = np.unique(level2_labels)\n",
    "            \n",
    "            for level2_id in unique_level2_labels:\n",
    "                # Get samples belonging to this Level 2 cluster\n",
    "                level1_mask = self.level1_labels == level1_id\n",
    "                level1_indices = np.where(level1_mask)[0]\n",
    "                level2_mask = level2_labels == level2_id\n",
    "                level2_indices = level1_indices[level2_mask]\n",
    "                \n",
    "                if len(level2_indices) < self.min_samples_per_final_cluster:\n",
    "                    print(f\"   Level 2 cluster ({level1_id}, {level2_id}): {len(level2_indices)} samples (too few for sub-sub-clustering)\")\n",
    "                    self.level3_labels[(level1_id, level2_id)] = np.zeros(len(level2_indices), dtype=int)\n",
    "                    continue\n",
    "                \n",
    "                # Create sub-sub-linkage matrix for this Level 2 cluster\n",
    "                sub_sub_linkage = self._create_sub_linkage_matrix(level2_indices, self.X_data)\n",
    "                \n",
    "                if sub_sub_linkage is not None:\n",
    "                    # Extract Level 3 clusters\n",
    "                    level3_labels = fcluster(sub_sub_linkage, \n",
    "                                           t=self.n_level3_clusters, \n",
    "                                           criterion='maxclust') - 1\n",
    "                    \n",
    "                    self.level3_labels[(level1_id, level2_id)] = level3_labels\n",
    "                    \n",
    "                    # Print Level 3 results\n",
    "                    unique_labels, counts = np.unique(level3_labels, return_counts=True)\n",
    "                    print(f\"   Level 2 cluster ({level1_id}, {level2_id}): {len(level2_indices)} samples ‚Üí {len(unique_labels)} sub-sub-clusters\")\n",
    "                    for subsub_label, count in zip(unique_labels, counts):\n",
    "                        print(f\"     Sub-sub-cluster {subsub_label}: {count} samples\")\n",
    "                else:\n",
    "                    print(f\"   Level 2 cluster ({level1_id}, {level2_id}): Could not create sub-sub-linkage matrix\")\n",
    "                    self.level3_labels[(level1_id, level2_id)] = np.zeros(len(level2_indices), dtype=int)\n",
    "    \n",
    "    def _create_sub_linkage_matrix(self, sample_indices, X_data):\n",
    "        \"\"\"\n",
    "        Create a sub-linkage matrix for a subset of samples.\n",
    "        This creates a new linkage matrix for the subset using the original data.\n",
    "        \"\"\"\n",
    "        if len(sample_indices) < 2:\n",
    "            return None\n",
    "        \n",
    "        # For very small subsets, we can't create meaningful sub-clusters\n",
    "        if len(sample_indices) <= 3:\n",
    "            return None\n",
    "        \n",
    "        try:\n",
    "            # Extract the subset of data\n",
    "            X_subset = X_data[sample_indices]\n",
    "            \n",
    "            # Calculate pairwise distances for the subset\n",
    "            distances = pdist(X_subset, metric='euclidean')\n",
    "            \n",
    "            # Create linkage matrix for the subset\n",
    "            sub_linkage = linkage(distances, method=self.linkage_method)\n",
    "            \n",
    "            return sub_linkage\n",
    "            \n",
    "        except Exception as e:\n",
    "            print(f\"   Error creating sub-linkage matrix: {e}\")\n",
    "            return None\n",
    "    \n",
    "    def _build_hierarchy(self):\n",
    "        \"\"\"Build the complete hierarchy structure.\"\"\"\n",
    "        self.sample_assignments = []\n",
    "        \n",
    "        for sample_idx in range(self.n_samples):\n",
    "            # Get Level 1 assignment\n",
    "            level1_id = self.level1_labels[sample_idx]\n",
    "            \n",
    "            # Get Level 2 assignment\n",
    "            level1_mask = self.level1_labels == level1_id\n",
    "            level1_indices = np.where(level1_mask)[0]\n",
    "            sample_position_in_level1 = np.where(level1_indices == sample_idx)[0][0]\n",
    "            level2_id = self.level2_labels[level1_id][sample_position_in_level1]\n",
    "            \n",
    "            # Get Level 3 assignment\n",
    "            level2_mask = self.level2_labels[level1_id] == level2_id\n",
    "            level2_indices = np.where(level1_mask)[0][level2_mask]\n",
    "            sample_position_in_level2 = np.where(level2_indices == sample_idx)[0][0]\n",
    "            level3_id = self.level3_labels[(level1_id, level2_id)][sample_position_in_level2]\n",
    "            \n",
    "            assignment = {\n",
    "                'sample_idx': sample_idx,\n",
    "                'sample_name': self.sample_names[sample_idx],\n",
    "                'level1_id': level1_id,\n",
    "                'level2_id': level2_id,\n",
    "                'level3_id': level3_id,\n",
    "                'full_path': f\"{level1_id}_{level2_id}_{level3_id}\"\n",
    "            }\n",
    "            \n",
    "            self.sample_assignments.append(assignment)\n",
    "        \n",
    "        # Build cluster hierarchy\n",
    "        self._build_cluster_hierarchy()\n",
    "    \n",
    "    def _build_cluster_hierarchy(self):\n",
    "        \"\"\"Build the cluster hierarchy structure.\"\"\"\n",
    "        self.cluster_hierarchy = {}\n",
    "        \n",
    "        # Level 1 clusters\n",
    "        for level1_id in range(len(np.unique(self.level1_labels))):\n",
    "            level1_samples = [a for a in self.sample_assignments if a['level1_id'] == level1_id]\n",
    "            \n",
    "            self.cluster_hierarchy[level1_id] = {\n",
    "                'level': 1,\n",
    "                'cluster_id': level1_id,\n",
    "                'sample_count': len(level1_samples),\n",
    "                'samples': level1_samples,\n",
    "                'children': {}\n",
    "            }\n",
    "            \n",
    "            # Level 2 clusters within this Level 1 cluster\n",
    "            unique_level2 = set(a['level2_id'] for a in level1_samples)\n",
    "            for level2_id in unique_level2:\n",
    "                level2_samples = [a for a in level1_samples if a['level2_id'] == level2_id]\n",
    "                \n",
    "                self.cluster_hierarchy[level1_id]['children'][level2_id] = {\n",
    "                    'level': 2,\n",
    "                    'cluster_id': level2_id,\n",
    "                    'sample_count': len(level2_samples),\n",
    "                    'samples': level2_samples,\n",
    "                    'children': {}\n",
    "                }\n",
    "                \n",
    "                # Level 3 clusters within this Level 2 cluster\n",
    "                unique_level3 = set(a['level3_id'] for a in level2_samples)\n",
    "                for level3_id in unique_level3:\n",
    "                    level3_samples = [a for a in level2_samples if a['level3_id'] == level3_id]\n",
    "                    \n",
    "                    self.cluster_hierarchy[level1_id]['children'][level2_id]['children'][level3_id] = {\n",
    "                        'level': 3,\n",
    "                        'cluster_id': level3_id,\n",
    "                        'sample_count': len(level3_samples),\n",
    "                        'samples': level3_samples,\n",
    "                        'children': {}\n",
    "                    }\n",
    "    \n",
    "    def _print_hierarchy_summary(self, show_samples=5, original_data=None, feature_names=None, floatfmt=\".2f\"):\n",
    "        \"\"\"\n",
    "        Print a summary of the clustering hierarchy.\n",
    "        \"\"\"\n",
    "        print(\"\\nüìä HIERARCHY SUMMARY\")\n",
    "        print(\"=\" * 50)\n",
    "        \n",
    "        total_final_clusters = 0\n",
    "\n",
    "        # Use the class's original_data if original_data not provided\n",
    "        if original_data is None:\n",
    "            if self.original_data is None:\n",
    "                print(\"No original data provided for sample display\")\n",
    "                return\n",
    "            original_data = self.original_data\n",
    "\n",
    "        # Setup: get indices (column numbers) for 'brand', 'price', 'category'\n",
    "        if hasattr(original_data, \"iloc\"):\n",
    "            original_data_arr = original_data.values\n",
    "            column_names = original_data.columns.tolist() if feature_names is None else feature_names\n",
    "        else:\n",
    "            original_data_arr = np.array(original_data)\n",
    "            column_names = [f\"feat_{i}\" for i in range(original_data.shape[1])] if feature_names is None else feature_names\n",
    "\n",
    "        # Find the indices of 'brand', 'price', and 'category'\n",
    "        def get_feature_idx(name):\n",
    "            try:\n",
    "                return column_names.index(name)\n",
    "            except ValueError:\n",
    "                print(f\"Warning: Required feature '{name}' not found in column names: {column_names}\")\n",
    "                return None\n",
    "        \n",
    "        brand_idx = get_feature_idx('brand')\n",
    "        price_idx = get_feature_idx('price')\n",
    "        category_idx = get_feature_idx('category')\n",
    "        \n",
    "        # Only show detailed info if we have the required features\n",
    "        show_detailed = all(idx is not None for idx in [brand_idx, price_idx, category_idx])\n",
    "        \n",
    "        if not show_detailed:\n",
    "            print(\"Note: Cannot show detailed sample information - missing required features\")\n",
    "\n",
    "        for level1_id, level1_data in self.cluster_hierarchy.items():\n",
    "            print(f\"Level 1 Cluster {level1_id}: {level1_data['sample_count']} samples\")\n",
    "            \n",
    "            for level2_id, level2_data in level1_data['children'].items():\n",
    "                print(f\"  Level 2 Cluster {level2_id}: {level2_data['sample_count']} samples\")\n",
    "                \n",
    "                for level3_id, level3_data in level2_data['children'].items():\n",
    "                    sample_indices = [a['sample_idx'] for a in level3_data['samples']]\n",
    "                    sample_count = level3_data['sample_count']\n",
    "                    total_final_clusters += 1\n",
    "                    print(f\"    Level 3 Cluster {level3_id}: {sample_count} samples\")\n",
    "                    \n",
    "                    if show_detailed and len(sample_indices) > 0:\n",
    "                        shown_indices = sample_indices[:show_samples]\n",
    "                        shown_data = original_data_arr[shown_indices]\n",
    "                        print(f\"      Showing up to {show_samples} samples (brand | price | category):\")\n",
    "                        for row in shown_data:\n",
    "                            to_show = []\n",
    "                            for idx in [brand_idx, price_idx, category_idx]:\n",
    "                                v = row[idx]\n",
    "                                # Format price/number if appropriate\n",
    "                                if idx == price_idx:\n",
    "                                    try:\n",
    "                                        to_show.append(f\"{float(v):{floatfmt}}\")\n",
    "                                    except Exception:\n",
    "                                        to_show.append(str(v))\n",
    "                                else:\n",
    "                                    to_show.append(str(v))\n",
    "                            print(f\"        {to_show[0]} | {to_show[1]} | {to_show[2]}\")\n",
    "        \n",
    "        print(f\"\\nüéØ Total final clusters: {total_final_clusters}\")\n",
    "        print(f\"üìà Average samples per final cluster: {self.n_samples / total_final_clusters:.1f}\")\n",
    "    \n",
    "    def get_cluster_path(self, sample_idx):\n",
    "        \"\"\"Get the complete cluster path for a sample.\"\"\"\n",
    "        if sample_idx >= len(self.sample_assignments):\n",
    "            return None\n",
    "        return self.sample_assignments[sample_idx]\n",
    "    \n",
    "    def predict(self, X):\n",
    "        \"\"\"\n",
    "        Predict cluster assignments for new samples.\n",
    "\n",
    "        Strategy:\n",
    "          - Assign each new sample the same level1/level2/level3 path as its nearest\n",
    "            neighbor in the training set (Euclidean distance on the features used\n",
    "            during fit). This is a simple and robust approach when using a\n",
    "            hierarchical model fitted on the original data.\n",
    "\n",
    "        Returns:\n",
    "          - list of dicts: each dict has keys:\n",
    "              'nearest_train_idx', 'level1_id', 'level2_id', 'level3_id', 'full_path'\n",
    "        \"\"\"\n",
    "        if self.sample_assignments is None or self.X_data is None:\n",
    "            raise RuntimeError(\"Model has not been fit yet. Call fit() before predict().\")\n",
    "        \n",
    "        X_arr = np.asarray(X)\n",
    "        if X_arr.ndim == 1:\n",
    "            X_arr = X_arr.reshape(1, -1)\n",
    "        \n",
    "        # Ensure dimensionality matches training data\n",
    "        if X_arr.shape[1] != self.X_data.shape[1]:\n",
    "            raise ValueError(f\"Input features dimension ({X_arr.shape[1]}) does not match training data ({self.X_data.shape[1]}).\")\n",
    "        \n",
    "        # Compute squared Euclidean distances between each query and training samples\n",
    "        # shape: (n_queries, n_train)\n",
    "        diffs = X_arr[:, None, :] - self.X_data[None, :, :]\n",
    "        dists = np.sum(diffs * diffs, axis=2)\n",
    "        nearest_idx = np.argmin(dists, axis=1)\n",
    "        \n",
    "        results = []\n",
    "        for q_idx, train_idx in enumerate(nearest_idx):\n",
    "            train_assignment = self.sample_assignments[int(train_idx)]\n",
    "            res = {\n",
    "                'nearest_train_idx': int(train_idx),\n",
    "                'level1_id': int(train_assignment['level1_id']),\n",
    "                'level2_id': int(train_assignment['level2_id']),\n",
    "                'level3_id': int(train_assignment['level3_id']),\n",
    "                'full_path': train_assignment['full_path']\n",
    "            }\n",
    "            results.append(res)\n",
    "        \n",
    "        return results\n",
    "    \n",
    "    def get_samples_in_cluster(self, level1_id, level2_id=None, level3_id=None):\n",
    "        \"\"\"Get all samples in a specific cluster at any level.\"\"\"\n",
    "        if level2_id is None:\n",
    "            # Level 1 cluster\n",
    "            return [a for a in self.sample_assignments if a['level1_id'] == level1_id]\n",
    "        elif level3_id is None:\n",
    "            # Level 2 cluster\n",
    "            return [a for a in self.sample_assignments \n",
    "                   if a['level1_id'] == level1_id and a['level2_id'] == level2_id]\n",
    "        else:\n",
    "            # Level 3 cluster\n",
    "            return [a for a in self.sample_assignments \n",
    "                   if a['level1_id'] == level1_id and a['level2_id'] == level2_id and a['level3_id'] == level3_id]\n",
    "    \n",
    "    def plot_dendrogram(self, max_display_levels=10, figsize=(12, 8)):\n",
    "        \"\"\"\n",
    "        Plot the dendrogram of the hierarchical clustering.\n",
    "        \n",
    "        Args:\n",
    "            max_display_levels: Maximum number of levels to display\n",
    "            figsize: Figure size tuple\n",
    "        \"\"\"\n",
    "        if self.linkage_matrix is None:\n",
    "            print(\"No linkage matrix available. Run fit() first.\")\n",
    "            return\n",
    "        \n",
    "        plt.figure(figsize=figsize)\n",
    "        dendrogram(self.linkage_matrix, \n",
    "                  truncate_mode='level', \n",
    "                  p=max_display_levels,\n",
    "                  show_leaf_counts=True,\n",
    "                  leaf_rotation=90.,\n",
    "                  leaf_font_size=12.,\n",
    "                  show_contracted=True)\n",
    "        plt.title('Hierarchical Clustering Dendrogram')\n",
    "        plt.xlabel('Sample Index or (cluster size)')\n",
    "        plt.ylabel('Distance')\n",
    "        plt.tight_layout()\n",
    "        plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "4f085be4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Testing Fixed SingleModelHierarchicalClustering\n",
      "============================================================\n",
      "üå≥ Starting Fixed Single Model Hierarchical Clustering\n",
      "üìä Data shape: (508, 96)\n",
      "üéØ Target clusters: Level 1=3, Level 2=4, Level 3=5\n",
      "üîó Linkage method: ward\n",
      "============================================================\n",
      "üìç Step 1: Creating linkage matrix...\n",
      "   Linkage matrix shape: (507, 4)\n",
      "üìç Step 2: Extracting Level 1 clusters...\n",
      "   Level 1 clusters: 3\n",
      "     Cluster 0: 101 samples\n",
      "     Cluster 1: 166 samples\n",
      "     Cluster 2: 241 samples\n",
      "üìç Step 3: Extracting Level 2 clusters...\n",
      "   Level 1 cluster 0: 101 samples ‚Üí 4 sub-clusters\n",
      "     Sub-cluster 0: 12 samples\n",
      "     Sub-cluster 1: 33 samples\n",
      "     Sub-cluster 2: 2 samples\n",
      "     Sub-cluster 3: 54 samples\n",
      "   Level 1 cluster 1: 166 samples ‚Üí 4 sub-clusters\n",
      "     Sub-cluster 0: 61 samples\n",
      "     Sub-cluster 1: 93 samples\n",
      "     Sub-cluster 2: 9 samples\n",
      "     Sub-cluster 3: 3 samples\n",
      "   Level 1 cluster 2: 241 samples ‚Üí 4 sub-clusters\n",
      "     Sub-cluster 0: 152 samples\n",
      "     Sub-cluster 1: 17 samples\n",
      "     Sub-cluster 2: 41 samples\n",
      "     Sub-cluster 3: 31 samples\n",
      "üìç Step 4: Extracting Level 3 clusters...\n",
      "   Level 2 cluster (0, 0): 12 samples ‚Üí 5 sub-sub-clusters\n",
      "     Sub-sub-cluster 0: 2 samples\n",
      "     Sub-sub-cluster 1: 2 samples\n",
      "     Sub-sub-cluster 2: 5 samples\n",
      "     Sub-sub-cluster 3: 2 samples\n",
      "     Sub-sub-cluster 4: 1 samples\n",
      "   Level 2 cluster (0, 1): 33 samples ‚Üí 5 sub-sub-clusters\n",
      "     Sub-sub-cluster 0: 6 samples\n",
      "     Sub-sub-cluster 1: 5 samples\n",
      "     Sub-sub-cluster 2: 15 samples\n",
      "     Sub-sub-cluster 3: 5 samples\n",
      "     Sub-sub-cluster 4: 2 samples\n",
      "   Level 2 cluster (0, 2): 2 samples (too few for sub-sub-clustering)\n",
      "   Level 2 cluster (0, 3): 54 samples ‚Üí 5 sub-sub-clusters\n",
      "     Sub-sub-cluster 0: 10 samples\n",
      "     Sub-sub-cluster 1: 22 samples\n",
      "     Sub-sub-cluster 2: 2 samples\n",
      "     Sub-sub-cluster 3: 19 samples\n",
      "     Sub-sub-cluster 4: 1 samples\n",
      "   Level 2 cluster (1, 0): 61 samples ‚Üí 5 sub-sub-clusters\n",
      "     Sub-sub-cluster 0: 2 samples\n",
      "     Sub-sub-cluster 1: 7 samples\n",
      "     Sub-sub-cluster 2: 10 samples\n",
      "     Sub-sub-cluster 3: 11 samples\n",
      "     Sub-sub-cluster 4: 31 samples\n",
      "   Level 2 cluster (1, 1): 93 samples ‚Üí 5 sub-sub-clusters\n",
      "     Sub-sub-cluster 0: 9 samples\n",
      "     Sub-sub-cluster 1: 5 samples\n",
      "     Sub-sub-cluster 2: 17 samples\n",
      "     Sub-sub-cluster 3: 7 samples\n",
      "     Sub-sub-cluster 4: 55 samples\n",
      "   Level 2 cluster (1, 2): 9 samples ‚Üí 5 sub-sub-clusters\n",
      "     Sub-sub-cluster 0: 2 samples\n",
      "     Sub-sub-cluster 1: 2 samples\n",
      "     Sub-sub-cluster 2: 2 samples\n",
      "     Sub-sub-cluster 3: 2 samples\n",
      "     Sub-sub-cluster 4: 1 samples\n",
      "   Level 2 cluster (1, 3): Could not create sub-sub-linkage matrix\n",
      "   Level 2 cluster (2, 0): 152 samples ‚Üí 5 sub-sub-clusters\n",
      "     Sub-sub-cluster 0: 47 samples\n",
      "     Sub-sub-cluster 1: 16 samples\n",
      "     Sub-sub-cluster 2: 31 samples\n",
      "     Sub-sub-cluster 3: 12 samples\n",
      "     Sub-sub-cluster 4: 46 samples\n",
      "   Level 2 cluster (2, 1): 17 samples ‚Üí 5 sub-sub-clusters\n",
      "     Sub-sub-cluster 0: 3 samples\n",
      "     Sub-sub-cluster 1: 4 samples\n",
      "     Sub-sub-cluster 2: 8 samples\n",
      "     Sub-sub-cluster 3: 1 samples\n",
      "     Sub-sub-cluster 4: 1 samples\n",
      "   Level 2 cluster (2, 2): 41 samples ‚Üí 5 sub-sub-clusters\n",
      "     Sub-sub-cluster 0: 8 samples\n",
      "     Sub-sub-cluster 1: 16 samples\n",
      "     Sub-sub-cluster 2: 2 samples\n",
      "     Sub-sub-cluster 3: 9 samples\n",
      "     Sub-sub-cluster 4: 6 samples\n",
      "   Level 2 cluster (2, 3): 31 samples ‚Üí 5 sub-sub-clusters\n",
      "     Sub-sub-cluster 0: 9 samples\n",
      "     Sub-sub-cluster 1: 14 samples\n",
      "     Sub-sub-cluster 2: 1 samples\n",
      "     Sub-sub-cluster 3: 6 samples\n",
      "     Sub-sub-cluster 4: 1 samples\n",
      "üìç Step 5: Building hierarchy...\n",
      "‚úÖ Fixed single model hierarchical clustering completed!\n",
      "\n",
      "üìä HIERARCHY SUMMARY\n",
      "==================================================\n",
      "Level 1 Cluster 0: 101 samples\n",
      "  Level 2 Cluster 0: 12 samples\n",
      "    Level 3 Cluster 0: 2 samples\n",
      "      Showing up to 5 samples (brand | price | category):\n",
      "        alcatel | nan | nan\n",
      "        alcatel | nan | nan\n",
      "    Level 3 Cluster 1: 2 samples\n",
      "      Showing up to 5 samples (brand | price | category):\n",
      "        miscellaneous | nan | low\n",
      "        miscellaneous | nan | low\n",
      "    Level 3 Cluster 2: 5 samples\n",
      "      Showing up to 5 samples (brand | price | category):\n",
      "        hanofer-mo | 13570300.00 | low\n",
      "        hanofer-mo | 21550000.00 | low\n",
      "        miscellaneous | 9890000.00 | low\n",
      "        miscellaneous | nan | low\n",
      "        miscellaneous | nan | nan\n",
      "    Level 3 Cluster 3: 2 samples\n",
      "      Showing up to 5 samples (brand | price | category):\n",
      "        ruggear | nan | nan\n",
      "        glx | nan | nan\n",
      "    Level 3 Cluster 4: 1 samples\n",
      "      Showing up to 5 samples (brand | price | category):\n",
      "        nokia | nan | low\n",
      "  Level 2 Cluster 1: 33 samples\n",
      "    Level 3 Cluster 0: 6 samples\n",
      "      Showing up to 5 samples (brand | price | category):\n",
      "        dox | nan | nan\n",
      "        dox | nan | low\n",
      "        dox | 17790000.00 | nan\n",
      "        dox | nan | nan\n",
      "        miscellaneous | nan | nan\n",
      "    Level 3 Cluster 1: 5 samples\n",
      "      Showing up to 5 samples (brand | price | category):\n",
      "        hanofer-mo | 14450000.00 | low\n",
      "        hanofer-mo | 10100000.00 | low\n",
      "        hanofer-mo | 6990000.00 | low\n",
      "        hanofer-mo | 9850000.00 | low\n",
      "        hanofer-mo | 10190000.00 | nan\n",
      "    Level 3 Cluster 2: 15 samples\n",
      "      Showing up to 5 samples (brand | price | category):\n",
      "        hanofer-mo | 11000000.00 | low\n",
      "        hanofer-mo | 10190000.00 | low\n",
      "        hanofer-mo | 12690000.00 | low\n",
      "        hanofer-mo | 16480300.00 | low\n",
      "        hanofer-mo | 12550000.00 | low\n",
      "    Level 3 Cluster 3: 5 samples\n",
      "      Showing up to 5 samples (brand | price | category):\n",
      "        hanofer-mo | 20950000.00 | low\n",
      "        hanofer-mo | 14650000.00 | low\n",
      "        hanofer-mo | 20350000.00 | low\n",
      "        hanofer-mo | 20100000.00 | low\n",
      "        hanofer-mo | 19700000.00 | low\n",
      "    Level 3 Cluster 4: 2 samples\n",
      "      Showing up to 5 samples (brand | price | category):\n",
      "        nokia | 32990000.00 | nan\n",
      "        alcatel | nan | nan\n",
      "  Level 2 Cluster 2: 2 samples\n",
      "    Level 3 Cluster 0: 2 samples\n",
      "      Showing up to 5 samples (brand | price | category):\n",
      "        glx | nan | low\n",
      "        dox | nan | low\n",
      "  Level 2 Cluster 3: 54 samples\n",
      "    Level 3 Cluster 0: 10 samples\n",
      "      Showing up to 5 samples (brand | price | category):\n",
      "        general-luxe-it | 16720000.00 | low\n",
      "        general-luxe-it | 12310000.00 | nan\n",
      "        general-luxe-it | 13950000.00 | nan\n",
      "        general-luxe-it | 20250000.00 | low\n",
      "        general-luxe-it | 19750000.00 | low\n",
      "    Level 3 Cluster 1: 22 samples\n",
      "      Showing up to 5 samples (brand | price | category):\n",
      "        other | 10450000.00 | low\n",
      "        other | 13390000.00 | low\n",
      "        glx | nan | nan\n",
      "        glx | nan | nan\n",
      "        glx | nan | nan\n",
      "    Level 3 Cluster 2: 2 samples\n",
      "      Showing up to 5 samples (brand | price | category):\n",
      "        nokia | 74990000.00 | nan\n",
      "        nokia | nan | nan\n",
      "    Level 3 Cluster 3: 19 samples\n",
      "      Showing up to 5 samples (brand | price | category):\n",
      "        glx | nan | nan\n",
      "        glx | nan | low\n",
      "        hanofer-mo | 10000000.00 | low\n",
      "        other | 8490000.00 | low\n",
      "        other | 9190000.00 | low\n",
      "    Level 3 Cluster 4: 1 samples\n",
      "      Showing up to 5 samples (brand | price | category):\n",
      "        glx | nan | nan\n",
      "Level 1 Cluster 1: 166 samples\n",
      "  Level 2 Cluster 0: 61 samples\n",
      "    Level 3 Cluster 0: 2 samples\n",
      "      Showing up to 5 samples (brand | price | category):\n",
      "        realme | nan | nan\n",
      "        realme | nan | nan\n",
      "    Level 3 Cluster 1: 7 samples\n",
      "      Showing up to 5 samples (brand | price | category):\n",
      "        nothing | nan | nan\n",
      "        nothing | nan | nan\n",
      "        nothing | nan | nan\n",
      "        tcl | nan | mid\n",
      "        motorola | nan | mid\n",
      "    Level 3 Cluster 2: 10 samples\n",
      "      Showing up to 5 samples (brand | price | category):\n",
      "        realme | nan | nan\n",
      "        realme | nan | nan\n",
      "        realme | nan | nan\n",
      "        oneplus | nan | mid\n",
      "        oneplus | nan | nan\n",
      "    Level 3 Cluster 3: 11 samples\n",
      "      Showing up to 5 samples (brand | price | category):\n",
      "        motorola | nan | high\n",
      "        motorola | nan | high\n",
      "        motorola | nan | high\n",
      "        oneplus | nan | nan\n",
      "        oneplus | nan | high\n",
      "    Level 3 Cluster 4: 31 samples\n",
      "      Showing up to 5 samples (brand | price | category):\n",
      "        apple | nan | high\n",
      "        apple | nan | mid\n",
      "        apple | nan | high\n",
      "        apple | nan | high\n",
      "        apple | nan | high\n",
      "  Level 2 Cluster 1: 93 samples\n",
      "    Level 3 Cluster 0: 9 samples\n",
      "      Showing up to 5 samples (brand | price | category):\n",
      "        apple | 2729980000.00 | high\n",
      "        apple | 1838990000.00 | high\n",
      "        apple | 2040000000.00 | high\n",
      "        apple | 1044990000.00 | high\n",
      "        apple | 1017990000.00 | high\n",
      "    Level 3 Cluster 1: 5 samples\n",
      "      Showing up to 5 samples (brand | price | category):\n",
      "        apple | 3120000000.00 | high\n",
      "        nothing | 898275000.00 | high\n",
      "        motorola | 614910000.00 | high\n",
      "        motorola | 382278000.00 | mid\n",
      "        samsung | 699990000.00 | mid\n",
      "    Level 3 Cluster 2: 17 samples\n",
      "      Showing up to 5 samples (brand | price | category):\n",
      "        xiaomi | 768000000.00 | mid\n",
      "        xiaomi | 1299900000.00 | nan\n",
      "        xiaomi | 815700000.00 | mid\n",
      "        xiaomi | 519990000.00 | mid\n",
      "        xiaomi | 609990000.00 | mid\n",
      "    Level 3 Cluster 3: 7 samples\n",
      "      Showing up to 5 samples (brand | price | category):\n",
      "        daria | 250865900.00 | high\n",
      "        daria | 267810000.00 | nan\n",
      "        daria | 138548000.00 | mid\n",
      "        daria | 150003000.00 | mid\n",
      "        daria | 126990000.00 | mid\n",
      "    Level 3 Cluster 4: 55 samples\n",
      "      Showing up to 5 samples (brand | price | category):\n",
      "        realme | 227990000.00 | high\n",
      "        realme | 254490000.00 | high\n",
      "        nothing | 529990000.00 | nan\n",
      "        nothing | 194373000.00 | mid\n",
      "        nothing | 968057000.00 | high\n",
      "  Level 2 Cluster 2: 9 samples\n",
      "    Level 3 Cluster 0: 2 samples\n",
      "      Showing up to 5 samples (brand | price | category):\n",
      "        daria | 110990000.00 | mid\n",
      "        samsung | nan | mid\n",
      "    Level 3 Cluster 1: 2 samples\n",
      "      Showing up to 5 samples (brand | price | category):\n",
      "        samsung | 325000000.00 | mid\n",
      "        samsung | 283966000.00 | mid\n",
      "    Level 3 Cluster 2: 2 samples\n",
      "      Showing up to 5 samples (brand | price | category):\n",
      "        samsung | 509990000.00 | mid\n",
      "        samsung | 406000000.00 | mid\n",
      "    Level 3 Cluster 3: 2 samples\n",
      "      Showing up to 5 samples (brand | price | category):\n",
      "        xiaomi | 174950000.00 | mid\n",
      "        xiaomi | 307000000.00 | mid\n",
      "    Level 3 Cluster 4: 1 samples\n",
      "      Showing up to 5 samples (brand | price | category):\n",
      "        samsung | 1315000000.00 | high\n",
      "  Level 2 Cluster 3: 3 samples\n",
      "    Level 3 Cluster 0: 3 samples\n",
      "      Showing up to 5 samples (brand | price | category):\n",
      "        apple | 814000000.00 | high\n",
      "        xiaomi | 209000000.00 | mid\n",
      "        samsung | nan | mid\n",
      "Level 1 Cluster 2: 241 samples\n",
      "  Level 2 Cluster 0: 152 samples\n",
      "    Level 3 Cluster 0: 47 samples\n",
      "      Showing up to 5 samples (brand | price | category):\n",
      "        realme | nan | mid\n",
      "        realme | nan | mid\n",
      "        realme | nan | mid\n",
      "        realme | nan | low\n",
      "        realme | nan | nan\n",
      "    Level 3 Cluster 1: 16 samples\n",
      "      Showing up to 5 samples (brand | price | category):\n",
      "        tecno-ma | 150341000.00 | mid\n",
      "        xiaomi | 246990000.00 | mid\n",
      "        xiaomi | 259051000.00 | nan\n",
      "        xiaomi | 248850000.00 | mid\n",
      "        xiaomi | 274990000.00 | mid\n",
      "    Level 3 Cluster 2: 31 samples\n",
      "      Showing up to 5 samples (brand | price | category):\n",
      "        xiaomi | 156993000.00 | low\n",
      "        xiaomi | 177990000.00 | mid\n",
      "        honor | 288186000.00 | mid\n",
      "        samsung | 167990000.00 | mid\n",
      "        samsung | 240832000.00 | low\n",
      "    Level 3 Cluster 3: 12 samples\n",
      "      Showing up to 5 samples (brand | price | category):\n",
      "        xiaomi | 190000000.00 | mid\n",
      "        xiaomi | 147490000.00 | low\n",
      "        xiaomi | 142900000.00 | nan\n",
      "        xiaomi | 142000000.00 | low\n",
      "        xiaomi | 141295000.00 | mid\n",
      "    Level 3 Cluster 4: 46 samples\n",
      "      Showing up to 5 samples (brand | price | category):\n",
      "        realme | nan | mid\n",
      "        realme | 89266000.00 | low\n",
      "        blackview | 109990000.00 | mid\n",
      "        blackview | 118300000.00 | mid\n",
      "        redtone | 122500000.00 | mid\n",
      "  Level 2 Cluster 1: 17 samples\n",
      "    Level 3 Cluster 0: 3 samples\n",
      "      Showing up to 5 samples (brand | price | category):\n",
      "        oneplus | nan | nan\n",
      "        oneplus | nan | high\n",
      "        oneplus | nan | mid\n",
      "    Level 3 Cluster 1: 4 samples\n",
      "      Showing up to 5 samples (brand | price | category):\n",
      "        apple | 1020000000.00 | high\n",
      "        apple | 769990000.00 | high\n",
      "        apple | 804900000.00 | high\n",
      "        apple | 1540000000.00 | high\n",
      "    Level 3 Cluster 2: 8 samples\n",
      "      Showing up to 5 samples (brand | price | category):\n",
      "        dox | nan | nan\n",
      "        blackberry | nan | nan\n",
      "        blackberry | nan | nan\n",
      "        blackberry | nan | nan\n",
      "        blackberry | nan | nan\n",
      "    Level 3 Cluster 3: 1 samples\n",
      "      Showing up to 5 samples (brand | price | category):\n",
      "        blackberry | nan | nan\n",
      "    Level 3 Cluster 4: 1 samples\n",
      "      Showing up to 5 samples (brand | price | category):\n",
      "        apple | nan | high\n",
      "  Level 2 Cluster 2: 41 samples\n",
      "    Level 3 Cluster 0: 8 samples\n",
      "      Showing up to 5 samples (brand | price | category):\n",
      "        blackview | nan | low\n",
      "        blackview | nan | low\n",
      "        blackview | nan | low\n",
      "        blackview | nan | mid\n",
      "        tecno-ma | nan | low\n",
      "    Level 3 Cluster 1: 16 samples\n",
      "      Showing up to 5 samples (brand | price | category):\n",
      "        realme | 100100000.00 | low\n",
      "        realme | nan | low\n",
      "        realme | 93000000.00 | low\n",
      "        realme | 117950000.00 | low\n",
      "        realme | 108000000.00 | mid\n",
      "    Level 3 Cluster 2: 2 samples\n",
      "      Showing up to 5 samples (brand | price | category):\n",
      "        xiaomi | 92000000.00 | low\n",
      "        samsung | 93990000.00 | nan\n",
      "    Level 3 Cluster 3: 9 samples\n",
      "      Showing up to 5 samples (brand | price | category):\n",
      "        general-luxe-it | 65094000.00 | low\n",
      "        hanofer-mo | 57990000.00 | nan\n",
      "        tch | 89990000.00 | low\n",
      "        tch | 79990000.00 | low\n",
      "        tcl | nan | low\n",
      "    Level 3 Cluster 4: 6 samples\n",
      "      Showing up to 5 samples (brand | price | category):\n",
      "        blackview | nan | nan\n",
      "        ruggear | nan | nan\n",
      "        ruggear | nan | nan\n",
      "        honor | nan | nan\n",
      "        honor | nan | nan\n",
      "  Level 2 Cluster 3: 31 samples\n",
      "    Level 3 Cluster 0: 9 samples\n",
      "      Showing up to 5 samples (brand | price | category):\n",
      "        glx | nan | nan\n",
      "        alcatel | nan | nan\n",
      "        alcatel | nan | nan\n",
      "        blackberry | nan | nan\n",
      "        blackberry | nan | nan\n",
      "    Level 3 Cluster 1: 14 samples\n",
      "      Showing up to 5 samples (brand | price | category):\n",
      "        blackview | nan | low\n",
      "        glx | nan | nan\n",
      "        tcl | nan | low\n",
      "        tcl | nan | low\n",
      "        miscellaneous | nan | nan\n",
      "    Level 3 Cluster 2: 1 samples\n",
      "      Showing up to 5 samples (brand | price | category):\n",
      "        miscellaneous | nan | nan\n",
      "    Level 3 Cluster 3: 6 samples\n",
      "      Showing up to 5 samples (brand | price | category):\n",
      "        ruggear | 57000000.00 | low\n",
      "        hanofer-mo | 31490000.00 | low\n",
      "        miscellaneous | nan | nan\n",
      "        alcatel | nan | nan\n",
      "        alcatel | nan | nan\n",
      "    Level 3 Cluster 4: 1 samples\n",
      "      Showing up to 5 samples (brand | price | category):\n",
      "        tcl | nan | mid\n",
      "\n",
      "üéØ Total final clusters: 52\n",
      "üìà Average samples per final cluster: 9.8\n",
      "Level 1 Silhouette Score: 0.3936\n",
      "Overall Average Silhouette: 0.3181\n",
      "Overall Average Davies-Bouldin Index: 1.1334\n",
      "Overall Average Calinski-Harabasz Index: 250.9523\n",
      "Metric                    Level 1      Level 2      Level 3      Average     \n",
      "--------------------------------------------------------------------------------\n",
      "Silhouette Score          0.3936       0.3269       0.2339       0.3181      \n",
      "Davies-Bouldin Index      1.0204       1.1966       1.1831       1.1334      \n",
      "Calinski-Harabasz Index   673.5385     67.6794      11.6391      250.9523    \n",
      "Level 1 Silhouette Score: 0.3936\n",
      "Overall Average Silhouette: 0.3181\n",
      "Overall Average Davies-Bouldin Index: 1.1334\n",
      "Overall Average Calinski-Harabasz Index: 250.9523\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/media/alireza/2ADF0001DEFFC2DD/KASEB/.venv/lib/python3.13/site-packages/mlflow/types/utils.py:452: UserWarning: Hint: Inferred schema contains integer column(s). Integer columns in Python cannot represent missing values. If your input data contains missing values at inference time, it will be encoded as floats and will cause a schema enforcement error. The best way to avoid this problem is to infer the model schema based on a realistic data sample (training dataset) that includes missing values. Alternatively, you can declare integer columns as doubles (float64) whenever these columns may have missing values. See `Handling Integers With Missing Values <https://www.mlflow.org/docs/latest/models.html#handling-integers-with-missing-values>`_ for more details.\n",
      "  warnings.warn(\n",
      "2025/10/29 18:32:24 WARNING mlflow.utils.environment: Failed to resolve installed pip version. ``pip`` will be added to conda.yaml environment spec without a version specifier.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üèÉ View run link_first at: http://127.0.0.1:8080/#/experiments/918627768166686221/runs/dafdf2eed4424619b36e0ef8ab75f797\n",
      "üß™ View experiment at: http://127.0.0.1:8080/#/experiments/918627768166686221\n"
     ]
    }
   ],
   "source": [
    "# Test the Fixed Implementation\n",
    "print(\"Testing Fixed SingleModelHierarchicalClustering\")\n",
    "print(\"=\" * 60)\n",
    "\n",
    "# Create sample data with clear clusters\n",
    "\n",
    "# Create sample data with 3 distinct clusters\n",
    "\n",
    "\n",
    "\n",
    "# Create an instance with smaller cluster numbers for testing\n",
    "fixed_clustering_link = FixedSingleModelHierarchicalClustering(\n",
    "    n_level1_clusters=3,      # Top-level clusters\n",
    "    n_level2_clusters=4,      # Sub-clusters within each Level 1 cluster\n",
    "    n_level3_clusters=5,      # Sub-sub-clusters within each Level 2 cluster\n",
    "    linkage_method='ward',     # Linkage method for hierarchical clustering\n",
    "    min_samples_per_final_cluster=3,\n",
    "    original_data = mobile\n",
    ")\n",
    "\n",
    "params = {\n",
    "    \"level1\" : 3,\n",
    "    \"level2\" : 4,\n",
    "    \"level3\": 5,\n",
    "    \"method\" : \"ward\"\n",
    "}\n",
    "# Fit on your transformed data\n",
    "sample_names = [f\"Mobile_{i}\" for i in range(len(transformed))] #TODO is it necessary ?\n",
    "\n",
    "tfd = transformed.copy()\n",
    "fixed_clustering_link.fit(tfd, sample_names)\n",
    "\n",
    "\n",
    "\n",
    "# Calculate all metrics\n",
    "metrics_results = calculate_all_clustering_metrics(fixed_clustering_link, transformed)\n",
    "\n",
    "# Or calculate individual metrics\n",
    "silhouette_scores = calculate_silhouette_score_nested(fixed_clustering_link, transformed)\n",
    "davies_bouldin_scores = calculate_davies_bouldin_score_nested(fixed_clustering_link, transformed)\n",
    "calinski_harabasz_scores = calculate_calinski_harabasz_score_nested(fixed_clustering_link, transformed)\n",
    "\n",
    "metrics = {\n",
    "    \"Silhouette Score\": silhouette_scores['average'],\n",
    "    \"Davies-Bouldin Index\": davies_bouldin_scores['average'],\n",
    "    \"Calinski-Harabasz Index\": calinski_harabasz_scores['average']\n",
    "}\n",
    "\n",
    "with mlflow.start_run(run_name=run_name_link):\n",
    "    mlflow.log_params(params)\n",
    "\n",
    "    mlflow.log_metrics(metrics)\n",
    "\n",
    "    mlflow.sklearn.log_model(sk_model=fixed_clustering_link,input_example=transformed[::50],name=artifact_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "77b61bcd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'nearest_train_idx': 131,\n",
       "  'level1_id': 0,\n",
       "  'level2_id': 1,\n",
       "  'level3_id': 1,\n",
       "  'full_path': '0_1_1'}]"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "fixed_clustering_link.predict(transformed[131])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "d82fc6cf",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Downloading artifacts: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 7/7 [00:00<00:00, 18.10it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[{'nearest_train_idx': 131, 'level1_id': 0, 'level2_id': 1, 'level3_id': 1, 'full_path': '0_1_1'}]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "\n",
    "model_name = \"Linkage\"\n",
    "model_version = \"1\"\n",
    "\n",
    "# Load the model from the Model Registry\n",
    "model_uri = f\"models:/{model_name}/{model_version}\"\n",
    "\n",
    "model = mlflow.sklearn.load_model(model_uri)\n",
    "# Generate a new dataset for prediction and predict\n",
    "y_pred_new = model.predict(transformed[131])\n",
    "\n",
    "print(y_pred_new)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5065372c",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "kaseb",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
